{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d0714e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv \n",
    "import geopandas as gpd\n",
    "from datetime import timedelta\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ed5fa590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv files and adjust to datetime\n",
    "C_im_date = pd.read_csv('../data/Cienega/CienegaImageryDates.csv', parse_dates=['date'])\n",
    "C_sur_date = pd.read_csv('../data/Cienega/Cienega_survey_dates.csv', parse_dates=['Cienega date'])\n",
    "C_sur_date['Cienega date'] = pd.to_datetime(C_sur_date['Cienega date'])\n",
    "C_im_date['date'] = pd.to_datetime(C_im_date['date'])\n",
    "\n",
    "C_hyd = pd.read_csv('../data/Cienega/CienegaHydroData.csv')\n",
    "C_hyd['datetime'] = pd.to_datetime(C_hyd['datetime'])\n",
    "\n",
    "C_precipitation = pd.read_csv('../data/Cienega/daymet_precip.csv')\n",
    "C_precipitation['system:time_start'] = pd.to_datetime(C_precipitation['system:time_start'])\n",
    "C_precipitation.rename( columns={'00000000000000000000':'P','system:time_start':'day'}, inplace=True )\n",
    "\n",
    "C_sur_date = C_sur_date.dropna(subset=['Cienega date'])\n",
    "C_im_date = C_im_date.dropna(subset=['date'])\n",
    "\n",
    "C_surveyData = pd.read_csv('../data/Cienega/Cienega_surveyData.csv')\n",
    "C_surveyData['Year'] = pd.to_datetime(C_surveyData['Year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "82e40101-6840-4b66-9463-fe3836524a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding closest matching dates between survey and imagery\n",
    "matching_dates = []\n",
    "tolerance = timedelta(days = 5)\n",
    "\n",
    "\n",
    "for date1 in C_sur_date['Cienega date']:\n",
    "    exact_date = False\n",
    "    tol = False \n",
    "    for date2 in C_im_date['date']:\n",
    "        if date1 == date2:\n",
    "            matching_dates.append({'Survey': date1, 'Imagery': date2})\n",
    "            exact_date = True\n",
    "    if not exact_date:\n",
    "        for date2 in C_im_date['date']:\n",
    "            if abs(date1 - date2) <= tolerance:\n",
    "                matching_dates.append({'Survey': date1, 'Imagery': date2})\n",
    "                tol = True\n",
    "        if not tol:\n",
    "            for date2 in C_im_date['date']:\n",
    "                if abs(date1-date2) < timedelta(days = 10): \n",
    "                    matching_dates.append({'Survey': date1, 'Imagery': date2})\n",
    "\n",
    "\n",
    "matching_dates_df = pd.DataFrame(matching_dates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "59fcdb11-21ef-486c-9453-2c804317ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging dfs to use to determine imagery dates for survey dates\n",
    "C_datessurData = pd.merge(matching_dates_df, C_hyd, left_on = 'Survey', right_on = 'datetime', how = 'left')\n",
    "C_datesimData = pd.merge(matching_dates_df, C_hyd, left_on = 'Imagery', right_on = 'datetime')\n",
    "C_datessurData = C_datessurData.drop(columns = ['Imagery','datetime'])\n",
    "C_datesimData = C_datesimData.drop(columns = ['Survey','datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b120b39f-b3a4-496f-a222-d238759841c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum precipitation for dates in between survey and imagery\n",
    "def sum_pdatesbetween(d1, d2):\n",
    "    r = pd.date_range(start=min(d1,d2), end=max(d1,d2))\n",
    "    return C_hyd[C_hyd['datetime'].isin(r)]['P [mm]'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "877e5aee-1bfa-41a2-a45d-7a31efc27e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe to determine which imagery dates to use\n",
    "Ch = pd.DataFrame([])\n",
    "\n",
    "Ch['Survey'] = matching_dates_df['Survey']\n",
    "Ch['Imagery'] = matching_dates_df['Imagery']\n",
    "Ch['sum_P'] = [sum_pdatesbetween(C_datessurData.loc[i, 'Survey'], C_datesimData.loc[i, 'Imagery']) for i in range(len(Ch))]\n",
    "Ch['Q_diff [%]'] = (C_datessurData['Q [mm/d]'] - C_datesimData['Q [mm/d]']) / C_datessurData['Q [mm/d]'] * 100\n",
    "Ch['Use/not'] = ['use', 'use', 'use', 'use', 'not', 'not', 'use?',\n",
    "                 'not', 'only option', 'not', 'not', 'use', 'not',\n",
    "                 'not', 'not', 'use', 'not', 'not', 'not', 'not',\n",
    "                 'use', 'use', 'use', 'only option','use', 'use', \n",
    "                 'use','use', 'not', 'not', 'not', 'not', 'use', \n",
    "                 'not', 'use', 'use', 'use', 'use', 'use', 'not', \n",
    "                 'not', 'not', 'not', 'use', 'not', 'not', 'not', \n",
    "                 'not', 'not', 'use', 'not', 'not', 'not', 'use', \n",
    "                 'not', 'use', 'use']\n",
    "\n",
    "\n",
    "conditions = (Ch['sum_P'] > 3) | (Ch['Q_diff [%]'] > 8) | (Ch['Use/not'] == 'not')\n",
    "\n",
    "Ch = Ch[~conditions]\n",
    "\n",
    "Ch = Ch.drop(columns=['Use/not'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b1d3a2e6-c9cf-4106-b335-dbf5ad595f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ch.to_csv('../data/Cienega/Cienega_survey_imagery_HydroData.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "880e49da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>wetdry</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (533719.252 3542427.373)</td>\n",
       "      <td>533719.252411</td>\n",
       "      <td>3.542427e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2015-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (533719.787 3542422.402)</td>\n",
       "      <td>533719.786671</td>\n",
       "      <td>3.542422e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2015-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (533720.321 3542417.431)</td>\n",
       "      <td>533720.320931</td>\n",
       "      <td>3.542417e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2015-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (533720.855 3542412.459)</td>\n",
       "      <td>533720.855191</td>\n",
       "      <td>3.542412e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2015-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (533721.389 3542407.488)</td>\n",
       "      <td>533721.389451</td>\n",
       "      <td>3.542407e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2015-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87148</th>\n",
       "      <td>POINT (533717.227 3542446.217)</td>\n",
       "      <td>533717.227336</td>\n",
       "      <td>3.542446e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2023-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87149</th>\n",
       "      <td>POINT (533717.762 3542441.246)</td>\n",
       "      <td>533717.761591</td>\n",
       "      <td>3.542441e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2023-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87150</th>\n",
       "      <td>POINT (533718.296 3542436.274)</td>\n",
       "      <td>533718.295846</td>\n",
       "      <td>3.542436e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2023-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87151</th>\n",
       "      <td>POINT (533718.83 3542431.303)</td>\n",
       "      <td>533718.830102</td>\n",
       "      <td>3.542431e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2023-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87152</th>\n",
       "      <td>POINT (539670.938 3540292.749)</td>\n",
       "      <td>539670.938285</td>\n",
       "      <td>3.540293e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2023-06-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87153 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             geometry              x             y wetdry  \\\n",
       "0      POINT (533719.252 3542427.373)  533719.252411  3.542427e+06    dry   \n",
       "1      POINT (533719.787 3542422.402)  533719.786671  3.542422e+06    dry   \n",
       "2      POINT (533720.321 3542417.431)  533720.320931  3.542417e+06    dry   \n",
       "3      POINT (533720.855 3542412.459)  533720.855191  3.542412e+06    dry   \n",
       "4      POINT (533721.389 3542407.488)  533721.389451  3.542407e+06    dry   \n",
       "...                               ...            ...           ...    ...   \n",
       "87148  POINT (533717.227 3542446.217)  533717.227336  3.542446e+06    dry   \n",
       "87149  POINT (533717.762 3542441.246)  533717.761591  3.542441e+06    dry   \n",
       "87150  POINT (533718.296 3542436.274)  533718.295846  3.542436e+06    dry   \n",
       "87151   POINT (533718.83 3542431.303)  533718.830102  3.542431e+06    dry   \n",
       "87152  POINT (539670.938 3540292.749)  539670.938285  3.540293e+06    dry   \n",
       "\n",
       "            Year  \n",
       "0     2015-12-09  \n",
       "1     2015-12-09  \n",
       "2     2015-12-09  \n",
       "3     2015-12-09  \n",
       "4     2015-12-09  \n",
       "...          ...  \n",
       "87148 2023-06-08  \n",
       "87149 2023-06-08  \n",
       "87150 2023-06-08  \n",
       "87151 2023-06-08  \n",
       "87152 2023-06-08  \n",
       "\n",
       "[87153 rows x 5 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading surveydata, making it into a geodataframe and adding x and y from the geometry to facilitate merge later \n",
    "C_surveyData['geometry'] = C_surveyData['geometry'].apply(wkt.loads)\n",
    "C_surveyData = C_surveyData.set_geometry('geometry')\n",
    "gdf = gpd.GeoDataFrame(C_surveyData, geometry = 'geometry')#, crs='EPSG:26912')\n",
    "gdf['x'] = gdf.geometry.x\n",
    "gdf['y'] = gdf.geometry.y\n",
    "gdf = gdf[['geometry', 'x', 'y', 'wetdry', 'Year']]\n",
    "gdf['Year'] = pd.to_datetime(gdf['Year'])\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fb368f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using new data for precipitation \n",
    "C_new_hyd = C_hyd.merge(C_precipitation, left_on = 'datetime', right_on = 'day')\n",
    "C_new_hyd = C_new_hyd.drop(columns = ['day', 'P [mm]'])\n",
    "C_new_hyd.rename( columns={'P':'P [mm]'}, inplace=True )\n",
    "C_new_hyd.set_index(['datetime'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e4057a74-ca6f-4dcc-936f-e46986f528f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to define assumptions around dates to choose, based on streamflow and precipitation\n",
    "# Q_condition could be completely removed\n",
    "def tolerance(Q_P_data, date, start, adjust, tolerance_p, P_condition = -999, Q_condition = -999):\n",
    "    \n",
    "    sub_grupp = Q_P_data.copy()\n",
    "    \n",
    "    if adjust == 'start':      \n",
    "        sub_grupp = Q_P_data.loc[start:].copy()       \n",
    "        \n",
    "    elif adjust == 'end': #reverse index to loop backwards\n",
    "        sub_grupp = sub_grupp.loc[:start].copy().iloc[::-1]        \n",
    "    \n",
    "    else:\n",
    "        print('Invalid adjust parameter. Please use \"start\" or \"end\"')\n",
    "        return\n",
    "\n",
    "    \n",
    "    # Reset index if reversed\n",
    "    sub_grupp.reset_index(inplace=True)\n",
    "\n",
    "    #creating a column for difference in streamflow\n",
    "    sub_grupp['Q_diff'] = sub_grupp['Q [mm/d]'].diff().fillna(0)\n",
    "\n",
    "    #checking to see if streamflow is overall decreasing, but a tolerance of x for any daily increase\n",
    "    if adjust == 'start':\n",
    "        sub_grupp['tolerance_condition'] = (sub_grupp.Q_diff < tolerance_p * sub_grupp['Q [mm/d]'])\n",
    "\n",
    "    if adjust == 'end':\n",
    "        sub_grupp['tolerance_condition'] = (sub_grupp.Q_diff > -tolerance_p * sub_grupp['Q [mm/d]'])\n",
    "\n",
    "    \n",
    "    if P_condition == -999 == Q_condition:\n",
    "        print('not a valid condition')\n",
    "        return \n",
    "        \n",
    "    elif P_condition == -999:\n",
    "        if Q_condition > 0:\n",
    "            sub_grupp['condition'] = sub_grupp['Q [mm/d]'] > Q_condition\n",
    "        else:\n",
    "            sub_grupp['condition'] = sub_grupp['Q [mm/d]'] < -Q_condition\n",
    "            \n",
    "    elif Q_condition == -999:\n",
    "        if P_condition > 0:\n",
    "            sub_grupp['condition'] = sub_grupp['P [mm]'] > P_condition\n",
    "        else:\n",
    "            sub_grupp['condition'] = sub_grupp['P [mm]'] < -P_condition\n",
    "            \n",
    "    else:\n",
    "        if (Q_condition > 0) & (P_condition > 0):\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] > Q_condition) & (sub_grupp['P [mm]'] > P_condition)\n",
    "        elif (Q_condition < 0) & (P_condition > 0):\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] < -Q_condition) & (sub_grupp['P [mm]'] > P_condition)           \n",
    "        elif (Q_condition > 0) & (P_condition < 0):\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] > Q_condition) & (sub_grupp['P [mm]'] < -P_condition)            \n",
    "        else:\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] < -Q_condition) & (sub_grupp['P [mm]'] < -P_condition)\n",
    "\n",
    "    # where both conditions are true\n",
    "    yesgroup = sub_grupp[(sub_grupp['condition'] == True) & (sub_grupp['tolerance_condition'] == True)] \n",
    "       \n",
    "    \n",
    "    if len(yesgroup) == 0:\n",
    "        print('No data where conditions are met')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    #the first instance where conditions are false after conditions hev been met \n",
    "    nogroup = sub_grupp[(sub_grupp['condition'] == False) | (sub_grupp['tolerance_condition'] == False)]  \n",
    "    \n",
    "    if len(nogroup) == 0:\n",
    "        print('nogroup = 0')\n",
    "        return sub_grupp.loc[yesgroup.index[0]:]\n",
    "\n",
    "    if yesgroup.index[0] < nogroup.index[0]:\n",
    "        print('everything is fine')\n",
    "        return sub_grupp.loc[:nogroup.index[0]]\n",
    "    \n",
    "    else:\n",
    "        print('No valid range found between yesgroup and nogroup indices')\n",
    "        return pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "04c2d444-ae00-4668-a2ea-b77826c40347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>wetdry</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>imagery</th>\n",
       "      <th>assumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>POINT (530539.306 3544473.636)</td>\n",
       "      <td>wet</td>\n",
       "      <td>530539.306440</td>\n",
       "      <td>3.544474e+06</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>assumed perennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>POINT (535121.159 3541964.946)</td>\n",
       "      <td>wet</td>\n",
       "      <td>535121.159176</td>\n",
       "      <td>3.541965e+06</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>assumed perennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>POINT (535150.805 3541960.347)</td>\n",
       "      <td>wet</td>\n",
       "      <td>535150.804694</td>\n",
       "      <td>3.541960e+06</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>assumed perennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>POINT (535145.864 3541961.114)</td>\n",
       "      <td>wet</td>\n",
       "      <td>535145.863775</td>\n",
       "      <td>3.541961e+06</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>assumed perennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>POINT (535155.746 3541959.581)</td>\n",
       "      <td>wet</td>\n",
       "      <td>535155.745614</td>\n",
       "      <td>3.541960e+06</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>assumed perennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54055</th>\n",
       "      <td>POINT (535395.445 3541912.99)</td>\n",
       "      <td>wet</td>\n",
       "      <td>535395.444692</td>\n",
       "      <td>3.541913e+06</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>assumed perennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54056</th>\n",
       "      <td>POINT (535390.777 3541914.781)</td>\n",
       "      <td>wet</td>\n",
       "      <td>535390.776535</td>\n",
       "      <td>3.541915e+06</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>assumed perennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54057</th>\n",
       "      <td>POINT (535386.108 3541916.572)</td>\n",
       "      <td>wet</td>\n",
       "      <td>535386.108378</td>\n",
       "      <td>3.541917e+06</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>assumed perennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54058</th>\n",
       "      <td>POINT (535381.44 3541918.363)</td>\n",
       "      <td>wet</td>\n",
       "      <td>535381.440221</td>\n",
       "      <td>3.541918e+06</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>assumed perennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54059</th>\n",
       "      <td>POINT (535376.772 3541920.154)</td>\n",
       "      <td>wet</td>\n",
       "      <td>535376.772064</td>\n",
       "      <td>3.541920e+06</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>assumed perennial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52560 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             geometry wetdry              x             y  \\\n",
       "60     POINT (530539.306 3544473.636)    wet  530539.306440  3.544474e+06   \n",
       "61     POINT (535121.159 3541964.946)    wet  535121.159176  3.541965e+06   \n",
       "62     POINT (535150.805 3541960.347)    wet  535150.804694  3.541960e+06   \n",
       "63     POINT (535145.864 3541961.114)    wet  535145.863775  3.541961e+06   \n",
       "64     POINT (535155.746 3541959.581)    wet  535155.745614  3.541960e+06   \n",
       "...                               ...    ...            ...           ...   \n",
       "54055   POINT (535395.445 3541912.99)    wet  535395.444692  3.541913e+06   \n",
       "54056  POINT (535390.777 3541914.781)    wet  535390.776535  3.541915e+06   \n",
       "54057  POINT (535386.108 3541916.572)    wet  535386.108378  3.541917e+06   \n",
       "54058   POINT (535381.44 3541918.363)    wet  535381.440221  3.541918e+06   \n",
       "54059  POINT (535376.772 3541920.154)    wet  535376.772064  3.541920e+06   \n",
       "\n",
       "         imagery         assumption  \n",
       "60    2016-11-17  assumed perennial  \n",
       "61    2016-11-17  assumed perennial  \n",
       "62    2016-11-17  assumed perennial  \n",
       "63    2016-11-17  assumed perennial  \n",
       "64    2016-11-17  assumed perennial  \n",
       "...          ...                ...  \n",
       "54055 2024-04-15  assumed perennial  \n",
       "54056 2024-04-15  assumed perennial  \n",
       "54057 2024-04-15  assumed perennial  \n",
       "54058 2024-04-15  assumed perennial  \n",
       "54059 2024-04-15  assumed perennial  \n",
       "\n",
       "[52560 rows x 6 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gdf['geometry_wkt'] = gdf['geometry'].apply(lambda geom: geom.wkt)\n",
    "# assuming perennial reaches\n",
    "perennial = pd.DataFrame(gdf[gdf.wetdry=='wet'].groupby('geometry').wetdry.count()).reset_index(drop=False)\n",
    "perennialcount = pd.DataFrame(gdf.groupby('geometry')['wetdry'].count()).reset_index(drop=False)\n",
    "\n",
    "# whichever number is reasonable based on data?\n",
    "perennial = perennial[(perennial['wetdry'] >= (perennialcount['wetdry']))]\n",
    "\n",
    "#assume always wet\n",
    "perennial = perennial.assign(wetdry = 'wet')\n",
    "#perennial['geometry'] = perennial['geometry_wkt'].apply(wkt.loads)\n",
    "#perennial = perennial.drop(columns=['geometry_wkt'])\n",
    "\n",
    "#perennial['geometry'] = perennial['geometry'].apply(wkt.loads)\n",
    "gdf_perennial = gpd.GeoDataFrame(perennial, geometry = 'geometry')#, crs='EPSG:26912')\n",
    "gdf_perennial['x'] = gdf_perennial.geometry.x\n",
    "gdf_perennial['y'] = gdf_perennial.geometry.y\n",
    "\n",
    "#making the gdf matching the perennial reaches to all the imagery dates available \n",
    "imagery_perennial = pd.concat([gdf_perennial.assign(imagery = date) for date in C_im_date['date']], ignore_index=True)\n",
    "imagery_perennial = imagery_perennial[~imagery_perennial['imagery'].isin(Ch['Imagery'])]\n",
    "imagery_perennial['assumption'] = len(imagery_perennial)*['assumed perennial']\n",
    "imagery_perennial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4872e688-f795-4a79-b427-cd8b2a6a2d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2016-06-03\n",
      "everything is fine\n",
      "No data for date 2016-09-23\n",
      "No valid range found between yesgroup and nogroup indices\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2016-03-18\n",
      "everything is fine\n",
      "No data for date 2017-06-09\n",
      "everything is fine\n",
      "No data for date 2017-09-19\n",
      "everything is fine\n",
      "No data for date 2017-12-08\n",
      "everything is fine\n",
      "No data for date 2017-03-16\n",
      "everything is fine\n",
      "No data for date 2018-06-05\n",
      "everything is fine\n",
      "No valid range found between yesgroup and nogroup indices\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2018-03-23\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2019-09-13\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2020-09-17\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "No valid range found between yesgroup and nogroup indices\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2022-12-15\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n"
     ]
    }
   ],
   "source": [
    "#assuming wet stretches for the dates before\n",
    "#assumption is made with 5 % difference in streamflow and for dates before survey when in a recession \n",
    "\n",
    "wet_list = []\n",
    "\n",
    "for date in C_surveyData['Year'].unique():\n",
    "            \n",
    "    wet1 = tolerance(C_new_hyd, 'datetime', date, 'end', 0.05, Q_condition = -999, P_condition = -1)\n",
    "    if len(wet1) == 0:\n",
    "        print('wet1 is empty')\n",
    "        continue\n",
    "    wet1 = wet1[~wet1['datetime'].isin(Ch['Imagery'])]\n",
    "    wet_imagery = pd.merge(wet1, C_im_date, left_on = ['datetime'], right_on = ['date'], how = 'inner')\n",
    "    #print(len(wet_imagery))\n",
    "    wet_points = pd.DataFrame(gdf[gdf['Year']== (date)].groupby('geometry')['wetdry'].apply(lambda x: sum(x == 'wet'))).reset_index(drop = False)\n",
    "    wet_points = wet_points[~wet_points['geometry'].isin(perennial['geometry'])]\n",
    "    wet_points = wet_points[(wet_points['wetdry'] == 1)]\n",
    "    wet_points = wet_points.assign(wetdry = 'wet')\n",
    "    wet_im_points = [wet_points.assign(imagery = date) for date in wet_imagery['date']]\n",
    "        \n",
    "    try:\n",
    "        wet = pd.concat(wet_im_points).drop(columns = ['level_1'])\n",
    "        wet_list.append(wet)\n",
    "    except:\n",
    "        if len(wet_im_points)==0:\n",
    "            print('No data for date '+ date.strftime('%Y-%m-%d'))\n",
    "        else:\n",
    "            wet = wet_im_points[0]\n",
    "            wet_list.append(wet)\n",
    "        \n",
    "\n",
    "wet_df = pd.concat(wet_list)\n",
    "\n",
    "\n",
    "wet_df['assumption'] = len(wet_df)*['assumed wet']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6e5e5c33-8b17-4ce7-ba72-25c2674500fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything is fine\n",
      "No data for date 2015-12-09\n",
      "everything is fine\n",
      "No data for date 2015-06-16\n",
      "everything is fine\n",
      "No data for date 2015-09-16\n",
      "everything is fine\n",
      "No data for date 2016-06-03\n",
      "everything is fine\n",
      "No data for date 2016-09-23\n",
      "No valid range found between yesgroup and nogroup indices\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2016-03-18\n",
      "everything is fine\n",
      "No data for date 2017-06-09\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2017-03-16\n",
      "everything is fine\n",
      "everything is fine\n",
      "No valid range found between yesgroup and nogroup indices\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2018-03-23\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2019-09-13\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "No valid range found between yesgroup and nogroup indices\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2022-03-18\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2022-09-08\n",
      "everything is fine\n",
      "everything is fine\n"
     ]
    }
   ],
   "source": [
    "#assuming dry stretches for the dates after\n",
    "#assumption is made with 5 % difference in streamflow and for dates after survey when in a recession \n",
    "\n",
    "dry_list = []\n",
    "\n",
    "\n",
    "for date in C_surveyData['Year'].unique():\n",
    "            \n",
    "    dry1 = tolerance(C_new_hyd, 'datetime', date, 'start', 0.05, Q_condition = -999, P_condition = -1)\n",
    "    if len(dry1) == 0:\n",
    "        print('wet1 is empty')\n",
    "        continue\n",
    "    dry1 = dry1[~dry1['datetime'].isin(Ch['Imagery'])]\n",
    "    dry_imagery = pd.merge(dry1, C_im_date, left_on = ['datetime'], right_on = ['date'], how = 'inner')\n",
    "        #print(len(wet_imagery))\n",
    "    dry_points = pd.DataFrame(gdf[gdf['Year']== (date)].groupby('geometry')['wetdry'].apply(lambda x: sum(x == 'dry'))).reset_index(drop = False)\n",
    "    dry_points = dry_points[(dry_points['wetdry'] == 1)].assign(wetdry = 'dry')\n",
    "    dry_im_points = [dry_points.assign(imagery = date) for date in dry_imagery['date']]\n",
    "        \n",
    "    try:\n",
    "        dry = pd.concat(dry_im_points).drop(columns = ['level_1'])\n",
    "        dry_list.append(dry)\n",
    "        \n",
    "    except:\n",
    "        if len(dry_im_points)==0:\n",
    "            print('No data for date '+ date.strftime('%Y-%m-%d'))\n",
    "        else:\n",
    "            dry = dry_im_points[0]\n",
    "            dry_list.append(dry)\n",
    "        #print(len(dry))\n",
    "        \n",
    "\n",
    "dry_df = pd.concat(dry_list)\n",
    "\n",
    "dry_df['assumption'] = len(dry_df)*['assumed dry']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a74226f7-cd05-4586-ae77-c66bd71a61ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>wetdry</th>\n",
       "      <th>assumption</th>\n",
       "      <th>Imagery</th>\n",
       "      <th>date_first</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (533719.252 3542427.373)</td>\n",
       "      <td>533719.252411</td>\n",
       "      <td>3.542427e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (533719.787 3542422.402)</td>\n",
       "      <td>533719.786671</td>\n",
       "      <td>3.542422e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (533720.321 3542417.431)</td>\n",
       "      <td>533720.320931</td>\n",
       "      <td>3.542417e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (533720.855 3542412.459)</td>\n",
       "      <td>533720.855191</td>\n",
       "      <td>3.542412e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (533721.389 3542407.488)</td>\n",
       "      <td>533721.389451</td>\n",
       "      <td>3.542407e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>POINT (539654.459 3540292.383)</td>\n",
       "      <td>539654.459252</td>\n",
       "      <td>3.540292e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>assumed dry</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-06-11</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>POINT (539659.459 3540292.405)</td>\n",
       "      <td>539659.459205</td>\n",
       "      <td>3.540292e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>assumed dry</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-06-11</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>POINT (539664.459 3540292.426)</td>\n",
       "      <td>539664.459158</td>\n",
       "      <td>3.540292e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>assumed dry</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-06-11</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>POINT (539670.938 3540292.749)</td>\n",
       "      <td>539670.938285</td>\n",
       "      <td>3.540293e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>assumed dry</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-06-11</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>POINT (539669.459 3540292.448)</td>\n",
       "      <td>539669.459111</td>\n",
       "      <td>3.540292e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>assumed dry</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-06-11</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182553 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            geometry              x             y wetdry  \\\n",
       "0     POINT (533719.252 3542427.373)  533719.252411  3.542427e+06    dry   \n",
       "1     POINT (533719.787 3542422.402)  533719.786671  3.542422e+06    dry   \n",
       "2     POINT (533720.321 3542417.431)  533720.320931  3.542417e+06    dry   \n",
       "3     POINT (533720.855 3542412.459)  533720.855191  3.542412e+06    dry   \n",
       "4     POINT (533721.389 3542407.488)  533721.389451  3.542407e+06    dry   \n",
       "...                              ...            ...           ...    ...   \n",
       "2592  POINT (539654.459 3540292.383)  539654.459252  3.540292e+06    dry   \n",
       "2593  POINT (539659.459 3540292.405)  539659.459205  3.540292e+06    dry   \n",
       "2594  POINT (539664.459 3540292.426)  539664.459158  3.540292e+06    dry   \n",
       "2595  POINT (539670.938 3540292.749)  539670.938285  3.540293e+06    dry   \n",
       "2596  POINT (539669.459 3540292.448)  539669.459111  3.540292e+06    dry   \n",
       "\n",
       "                assumption Imagery date_first       date  \n",
       "0     survey/imagery match     NaT        NaT        NaT  \n",
       "1     survey/imagery match     NaT        NaT        NaT  \n",
       "2     survey/imagery match     NaT        NaT        NaT  \n",
       "3     survey/imagery match     NaT        NaT        NaT  \n",
       "4     survey/imagery match     NaT        NaT        NaT  \n",
       "...                    ...     ...        ...        ...  \n",
       "2592           assumed dry     NaT 2023-06-11 2023-06-11  \n",
       "2593           assumed dry     NaT 2023-06-11 2023-06-11  \n",
       "2594           assumed dry     NaT 2023-06-11 2023-06-11  \n",
       "2595           assumed dry     NaT 2023-06-11 2023-06-11  \n",
       "2596           assumed dry     NaT 2023-06-11 2023-06-11  \n",
       "\n",
       "[182553 rows x 8 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate all dfs with assumptions and survey matched to imagery dates and turn to gdf\n",
    "gdf['assumption'] = len(gdf)*['survey/imagery match']\n",
    "gdf_imagery = pd.merge(gdf, Ch, left_on = 'Year', right_on = 'Survey', how = 'left')\n",
    "gdf_imagery = gdf_imagery.drop(columns=['Survey', 'sum_P', 'Q_diff [%]', 'Year'])\n",
    "all_expanded = pd.concat([gdf_imagery, imagery_perennial, wet_df, dry_df])\n",
    "all_expanded = gpd.GeoDataFrame(all_expanded, geometry = 'geometry')#, crs='EPSG:26912')\n",
    "all_expanded['x'] = all_expanded.geometry.x\n",
    "all_expanded['y'] = all_expanded.geometry.y\n",
    "all_expanded = all_expanded.rename(columns = {'imagery':'date_first'})\n",
    "all_expanded['date'] = all_expanded['Imagery'].combine_first(all_expanded['date_first'])\n",
    "all_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f8449ef5-28ea-4775-89aa-fa061a7c64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading and concatenating the processed imagery \n",
    "path = '../data/Cienega/processed_imagery'\n",
    "\n",
    "processed_imagery = glob.glob(path + '/*.csv')\n",
    "processed_imagery.sort(key = lambda x: int(x.split('_buffer_')[1].split('.')[0]))\n",
    "con_ready_imagery = []\n",
    "for processed in processed_imagery:\n",
    "    df= pd.read_csv(processed)\n",
    "    con_ready_imagery.append(df)\n",
    "\n",
    "concatenated = pd.concat(con_ready_imagery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c8e02208-2077-4fef-a1e0-6bd15b6c1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated['geometry'] = concatenated['geometry'].apply(wkt.loads)\n",
    "gdf_processed = gpd.GeoDataFrame(concatenated, geometry = 'geometry')#, crs='EPSG:26912')\n",
    "gdf_processed['date'] = pd.to_datetime(gdf_processed['date'], format='%Y%m%d')\n",
    "gdf_processed['x'] = gdf_processed.geometry.x\n",
    "gdf_processed['y'] = gdf_processed.geometry.y\n",
    "gdf_processed = gdf_processed.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4264da09-bd77-43ca-bb2d-745ea3af7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 6\n",
    "all_expanded['x'] = all_expanded['x'].round(precision)\n",
    "all_expanded['y'] = all_expanded['y'].round(precision)\n",
    "gdf_processed['x'] = gdf_processed['x'].round(precision)\n",
    "gdf_processed['y'] = gdf_processed['y'].round(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f609f457-9b11-4a8b-aa11-2c9177bd3578",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = all_expanded.merge(gdf_processed, on=['date', 'x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "448f9ab5-691c-4e20-8ce2-80d629ba6f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>wetdry</th>\n",
       "      <th>assumption</th>\n",
       "      <th>date</th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "      <th>NIR</th>\n",
       "      <th>missing</th>\n",
       "      <th>NDWI</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>534451.929516</td>\n",
       "      <td>3.542234e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>1124.56</td>\n",
       "      <td>1395.33</td>\n",
       "      <td>1837.78</td>\n",
       "      <td>2920.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>534446.929543</td>\n",
       "      <td>3.542234e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>1089.56</td>\n",
       "      <td>1368.11</td>\n",
       "      <td>1801.33</td>\n",
       "      <td>2846.22</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>534441.929569</td>\n",
       "      <td>3.542234e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>1073.56</td>\n",
       "      <td>1343.22</td>\n",
       "      <td>1780.00</td>\n",
       "      <td>2792.22</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>534455.700434</td>\n",
       "      <td>3.542231e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>944.22</td>\n",
       "      <td>1228.11</td>\n",
       "      <td>1619.22</td>\n",
       "      <td>2888.56</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>534436.929596</td>\n",
       "      <td>3.542234e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>997.56</td>\n",
       "      <td>1270.00</td>\n",
       "      <td>1691.44</td>\n",
       "      <td>2742.11</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337330</th>\n",
       "      <td>535200.213892</td>\n",
       "      <td>3.541953e+06</td>\n",
       "      <td>wet</td>\n",
       "      <td>assumed perennial</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>281.11</td>\n",
       "      <td>596.00</td>\n",
       "      <td>554.44</td>\n",
       "      <td>2676.67</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337329</th>\n",
       "      <td>535200.213892</td>\n",
       "      <td>3.541953e+06</td>\n",
       "      <td>wet</td>\n",
       "      <td>assumed perennial</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>184.00</td>\n",
       "      <td>523.22</td>\n",
       "      <td>463.33</td>\n",
       "      <td>2433.44</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337328</th>\n",
       "      <td>535200.213892</td>\n",
       "      <td>3.541953e+06</td>\n",
       "      <td>wet</td>\n",
       "      <td>assumed perennial</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>265.11</td>\n",
       "      <td>576.00</td>\n",
       "      <td>536.33</td>\n",
       "      <td>2583.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337326</th>\n",
       "      <td>535205.154812</td>\n",
       "      <td>3.541952e+06</td>\n",
       "      <td>wet</td>\n",
       "      <td>assumed perennial</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>565.00</td>\n",
       "      <td>1022.78</td>\n",
       "      <td>1410.56</td>\n",
       "      <td>2407.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337531</th>\n",
       "      <td>535376.772064</td>\n",
       "      <td>3.541920e+06</td>\n",
       "      <td>wet</td>\n",
       "      <td>assumed perennial</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>665.33</td>\n",
       "      <td>1100.78</td>\n",
       "      <td>1386.67</td>\n",
       "      <td>2619.89</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316852 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    x             y wetdry            assumption       date  \\\n",
       "3525    534451.929516  3.542234e+06    dry  survey/imagery match 2016-09-22   \n",
       "3523    534446.929543  3.542234e+06    dry  survey/imagery match 2016-09-22   \n",
       "3521    534441.929569  3.542234e+06    dry  survey/imagery match 2016-09-22   \n",
       "3527    534455.700434  3.542231e+06    dry  survey/imagery match 2016-09-22   \n",
       "3519    534436.929596  3.542234e+06    dry  survey/imagery match 2016-09-22   \n",
       "...               ...           ...    ...                   ...        ...   \n",
       "337330  535200.213892  3.541953e+06    wet     assumed perennial 2024-04-15   \n",
       "337329  535200.213892  3.541953e+06    wet     assumed perennial 2024-04-15   \n",
       "337328  535200.213892  3.541953e+06    wet     assumed perennial 2024-04-15   \n",
       "337326  535205.154812  3.541952e+06    wet     assumed perennial 2024-04-15   \n",
       "337531  535376.772064  3.541920e+06    wet     assumed perennial 2024-04-15   \n",
       "\n",
       "           blue    green      red      NIR  missing  NDWI  p  \n",
       "3525    1124.56  1395.33  1837.78  2920.00        0 -0.35  0  \n",
       "3523    1089.56  1368.11  1801.33  2846.22        0 -0.35  0  \n",
       "3521    1073.56  1343.22  1780.00  2792.22        0 -0.35  0  \n",
       "3527     944.22  1228.11  1619.22  2888.56        0 -0.40  0  \n",
       "3519     997.56  1270.00  1691.44  2742.11        0 -0.37  0  \n",
       "...         ...      ...      ...      ...      ...   ... ..  \n",
       "337330   281.11   596.00   554.44  2676.67        0 -0.64  0  \n",
       "337329   184.00   523.22   463.33  2433.44        0 -0.65  0  \n",
       "337328   265.11   576.00   536.33  2583.00        0 -0.64  0  \n",
       "337326   565.00  1022.78  1410.56  2407.00        0 -0.40  0  \n",
       "337531   665.33  1100.78  1386.67  2619.89        0 -0.41  0  \n",
       "\n",
       "[316852 rows x 12 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = merged.drop(columns = ['geometry_x', 'geometry_y', 'Imagery', 'date_first']) \n",
    "merged_sorted = merged.sort_values(by='date')\n",
    "merged_sorted = merged_sorted.drop_duplicates()\n",
    "merged_sorted.dropna(inplace= True)\n",
    "merged_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "482dd362-9c0c-4157-a19c-79cccbaee270",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "splitnum = 10\n",
    "for i in range(1,splitnum+1):\n",
    "    newstart = int(len(merged_sorted)/splitnum*i)\n",
    "    merged_sorted.iloc[start:newstart].to_csv('../data/Cienega/processed_assumptions/processed_with_dates_and_assumptions_new'+str(i)+'.csv',index=False,\n",
    "                      float_format='%.2f')\n",
    "    start = newstart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000cf055-8029-4d76-a6d5-65a3d1b956c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452e608-c3ce-4b94-a3f8-a24e228ff95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6bf3f9-ba52-45bc-be7c-6f9368ec2451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
