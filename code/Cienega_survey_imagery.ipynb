{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0714e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv \n",
    "import geopandas as gpd\n",
    "from datetime import timedelta\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed5fa590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv files and adjust to datetime\n",
    "C_im_date = pd.read_csv('../data/Cienega/CienegaImageryDates.csv', parse_dates=['date'])\n",
    "C_sur_date = pd.read_csv('../data/Cienega/Cienega_survey_dates.csv', parse_dates=['Cienega date'])\n",
    "C_sur_date['Cienega date'] = pd.to_datetime(C_sur_date['Cienega date'])\n",
    "C_im_date['date'] = pd.to_datetime(C_im_date['date'])\n",
    "\n",
    "C_hyd = pd.read_csv('../data/Cienega/CienegaHydroData.csv')\n",
    "C_hyd['datetime'] = pd.to_datetime(C_hyd['datetime'])\n",
    "\n",
    "C_precipitation = pd.read_csv('../data/Cienega/daymet_precip.csv')\n",
    "C_precipitation['system:time_start'] = pd.to_datetime(C_precipitation['system:time_start'])\n",
    "C_precipitation.rename( columns={'00000000000000000000':'P','system:time_start':'day'}, inplace=True )\n",
    "\n",
    "C_sur_date = C_sur_date.dropna(subset=['Cienega date'])\n",
    "C_im_date = C_im_date.dropna(subset=['date'])\n",
    "\n",
    "C_surveyData = pd.read_csv('../data/Cienega/Cienega_surveyData.csv')\n",
    "C_surveyData['Year'] = pd.to_datetime(C_surveyData['Year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82e40101-6840-4b66-9463-fe3836524a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding closest matching dates between survey and imagery\n",
    "matching_dates = []\n",
    "tolerance = timedelta(days = 5)\n",
    "\n",
    "\n",
    "for date1 in C_sur_date['Cienega date']:\n",
    "    exact_date = False\n",
    "    tol = False \n",
    "    for date2 in C_im_date['date']:\n",
    "        if date1 == date2:\n",
    "            matching_dates.append({'Survey': date1, 'Imagery': date2})\n",
    "            exact_date = True\n",
    "    if not exact_date:\n",
    "        for date2 in C_im_date['date']:\n",
    "            if abs(date1 - date2) <= tolerance:\n",
    "                matching_dates.append({'Survey': date1, 'Imagery': date2})\n",
    "                tol = True\n",
    "        if not tol:\n",
    "            for date2 in C_im_date['date']:\n",
    "                if abs(date1-date2) < timedelta(days = 10): \n",
    "                    matching_dates.append({'Survey': date1, 'Imagery': date2})\n",
    "\n",
    "\n",
    "matching_dates_df = pd.DataFrame(matching_dates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59fcdb11-21ef-486c-9453-2c804317ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging dfs to use to determine imagery dates for survey dates\n",
    "C_datessurData = pd.merge(matching_dates_df, C_hyd, left_on = 'Survey', right_on = 'datetime', how = 'left')\n",
    "C_datesimData = pd.merge(matching_dates_df, C_hyd, left_on = 'Imagery', right_on = 'datetime')\n",
    "C_datessurData = C_datessurData.drop(columns = ['Imagery','datetime'])\n",
    "C_datesimData = C_datesimData.drop(columns = ['Survey','datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b120b39f-b3a4-496f-a222-d238759841c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum precipitation for dates in between survey and imagery\n",
    "def sum_pdatesbetween(d1, d2):\n",
    "    r = pd.date_range(start=min(d1,d2), end=max(d1,d2))\n",
    "    return C_hyd[C_hyd['datetime'].isin(r)]['P [mm]'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "877e5aee-1bfa-41a2-a45d-7a31efc27e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe to determine which imagery dates to use\n",
    "Ch = pd.DataFrame([])\n",
    "\n",
    "Ch['Survey'] = matching_dates_df['Survey']\n",
    "Ch['Imagery'] = matching_dates_df['Imagery']\n",
    "Ch['sum_P'] = [sum_pdatesbetween(C_datessurData.loc[i, 'Survey'], C_datesimData.loc[i, 'Imagery']) for i in range(len(Ch))]\n",
    "Ch['Q_diff [%]'] = (C_datessurData['Q [mm/d]'] - C_datesimData['Q [mm/d]']) / C_datessurData['Q [mm/d]'] * 100\n",
    "Ch['Use/not'] = ['use', 'use', 'use', 'use', 'not', 'not', 'use?',\n",
    "                 'not', 'only option', 'not', 'not', 'use', 'not',\n",
    "                 'not', 'not', 'use', 'not', 'not', 'not', 'not',\n",
    "                 'use', 'use', 'use', 'only option','use', 'use', \n",
    "                 'use','use', 'not', 'not', 'not', 'not', 'use', \n",
    "                 'not', 'use', 'use', 'use', 'use', 'use', 'not', \n",
    "                 'not', 'not', 'not', 'use', 'not', 'not', 'not', \n",
    "                 'not', 'not', 'use', 'not', 'not', 'not', 'use', \n",
    "                 'not', 'use', 'use']\n",
    "\n",
    "\n",
    "conditions = (Ch['sum_P'] > 3) | (Ch['Q_diff [%]'] > 8) | (Ch['Use/not'] == 'not')\n",
    "\n",
    "Ch = Ch[~conditions]\n",
    "\n",
    "Ch = Ch.drop(columns=['Use/not'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1d3a2e6-c9cf-4106-b335-dbf5ad595f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ch.to_csv('../data/Cienega/Cienega_survey_imagery_HydroData.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "880e49da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>wetdry</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (533719.252 3542427.373)</td>\n",
       "      <td>533719.252411</td>\n",
       "      <td>3.542427e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2004-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (533719.787 3542422.402)</td>\n",
       "      <td>533719.786671</td>\n",
       "      <td>3.542422e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2004-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (533720.321 3542417.431)</td>\n",
       "      <td>533720.320931</td>\n",
       "      <td>3.542417e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2004-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (533720.855 3542412.459)</td>\n",
       "      <td>533720.855191</td>\n",
       "      <td>3.542412e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2004-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (533721.389 3542407.488)</td>\n",
       "      <td>533721.389451</td>\n",
       "      <td>3.542407e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2004-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237685</th>\n",
       "      <td>POINT (533717.227 3542446.217)</td>\n",
       "      <td>533717.227336</td>\n",
       "      <td>3.542446e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2013-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237686</th>\n",
       "      <td>POINT (533717.762 3542441.246)</td>\n",
       "      <td>533717.761591</td>\n",
       "      <td>3.542441e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2013-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237687</th>\n",
       "      <td>POINT (533718.296 3542436.274)</td>\n",
       "      <td>533718.295846</td>\n",
       "      <td>3.542436e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2013-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237688</th>\n",
       "      <td>POINT (533718.830 3542431.303)</td>\n",
       "      <td>533718.830102</td>\n",
       "      <td>3.542431e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2013-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237689</th>\n",
       "      <td>POINT (539670.938 3540292.749)</td>\n",
       "      <td>539670.938285</td>\n",
       "      <td>3.540293e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2013-09-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237690 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              geometry              x             y wetdry  \\\n",
       "0       POINT (533719.252 3542427.373)  533719.252411  3.542427e+06    dry   \n",
       "1       POINT (533719.787 3542422.402)  533719.786671  3.542422e+06    dry   \n",
       "2       POINT (533720.321 3542417.431)  533720.320931  3.542417e+06    dry   \n",
       "3       POINT (533720.855 3542412.459)  533720.855191  3.542412e+06    dry   \n",
       "4       POINT (533721.389 3542407.488)  533721.389451  3.542407e+06    dry   \n",
       "...                                ...            ...           ...    ...   \n",
       "237685  POINT (533717.227 3542446.217)  533717.227336  3.542446e+06    dry   \n",
       "237686  POINT (533717.762 3542441.246)  533717.761591  3.542441e+06    dry   \n",
       "237687  POINT (533718.296 3542436.274)  533718.295846  3.542436e+06    dry   \n",
       "237688  POINT (533718.830 3542431.303)  533718.830102  3.542431e+06    dry   \n",
       "237689  POINT (539670.938 3540292.749)  539670.938285  3.540293e+06    dry   \n",
       "\n",
       "             Year  \n",
       "0      2004-06-25  \n",
       "1      2004-06-25  \n",
       "2      2004-06-25  \n",
       "3      2004-06-25  \n",
       "4      2004-06-25  \n",
       "...           ...  \n",
       "237685 2013-09-05  \n",
       "237686 2013-09-05  \n",
       "237687 2013-09-05  \n",
       "237688 2013-09-05  \n",
       "237689 2013-09-05  \n",
       "\n",
       "[237690 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading surveydata, making it into a geodataframe and adding x and y from the geometry to facilitate merge later \n",
    "C_surveyData['geometry'] = C_surveyData['geometry'].apply(wkt.loads)\n",
    "C_surveyData = C_surveyData.set_geometry('geometry')\n",
    "gdf = gpd.GeoDataFrame(C_surveyData, geometry = 'geometry')#, crs='EPSG:26912')\n",
    "gdf['x'] = gdf.geometry.x\n",
    "gdf['y'] = gdf.geometry.y\n",
    "gdf = gdf[['geometry', 'x', 'y', 'wetdry', 'Year']]\n",
    "gdf['Year'] = pd.to_datetime(gdf['Year'])\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb368f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using new data for precipitation \n",
    "C_new_hyd = C_hyd.merge(C_precipitation, left_on = 'datetime', right_on = 'day')\n",
    "C_new_hyd = C_new_hyd.drop(columns = ['day', 'P [mm]'])\n",
    "C_new_hyd.rename( columns={'P':'P [mm]'}, inplace=True )\n",
    "C_new_hyd.set_index(['datetime'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4057a74-ca6f-4dcc-936f-e46986f528f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to define assumptions around dates to choose, based on streamflow and precipitation\n",
    "# Q_condition could be completely removed\n",
    "def tolerance(Q_P_data, date, start, adjust, tolerance_p, P_condition = -999, Q_condition = -999):\n",
    "    \n",
    "    sub_grupp = Q_P_data.copy()\n",
    "    \n",
    "    if adjust == 'start':      \n",
    "        sub_grupp = Q_P_data.loc[start:].copy()       \n",
    "        \n",
    "    elif adjust == 'end': #reverse index to loop backwards\n",
    "        sub_grupp = sub_grupp.loc[:start].copy().iloc[::-1]        \n",
    "    \n",
    "    else:\n",
    "        print('Invalid adjust parameter. Please use \"start\" or \"end\"')\n",
    "        return\n",
    "\n",
    "    \n",
    "    # Reset index if reversed\n",
    "    sub_grupp.reset_index(inplace=True)\n",
    "\n",
    "    #creating a column for difference in streamflow\n",
    "    sub_grupp['Q_diff'] = sub_grupp['Q [mm/d]'].diff().fillna(0)\n",
    "\n",
    "    #checking to see if streamflow is overall decreasing, but a tolerance of x for any daily increase\n",
    "    if adjust == 'start':\n",
    "        sub_grupp['tolerance_condition'] = (sub_grupp.Q_diff < tolerance_p * sub_grupp['Q [mm/d]'])\n",
    "\n",
    "    if adjust == 'end':\n",
    "        sub_grupp['tolerance_condition'] = (sub_grupp.Q_diff > -tolerance_p * sub_grupp['Q [mm/d]'])\n",
    "\n",
    "    \n",
    "    if P_condition == -999 == Q_condition:\n",
    "        print('not a valid condition')\n",
    "        return \n",
    "        \n",
    "    elif P_condition == -999:\n",
    "        if Q_condition > 0:\n",
    "            sub_grupp['condition'] = sub_grupp['Q [mm/d]'] > Q_condition\n",
    "        else:\n",
    "            sub_grupp['condition'] = sub_grupp['Q [mm/d]'] < -Q_condition\n",
    "            \n",
    "    elif Q_condition == -999:\n",
    "        if P_condition > 0:\n",
    "            sub_grupp['condition'] = sub_grupp['P [mm]'] > P_condition\n",
    "        else:\n",
    "            sub_grupp['condition'] = sub_grupp['P [mm]'] < -P_condition\n",
    "            \n",
    "    else:\n",
    "        if (Q_condition > 0) & (P_condition > 0):\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] > Q_condition) & (sub_grupp['P [mm]'] > P_condition)\n",
    "        elif (Q_condition < 0) & (P_condition > 0):\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] < -Q_condition) & (sub_grupp['P [mm]'] > P_condition)           \n",
    "        elif (Q_condition > 0) & (P_condition < 0):\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] > Q_condition) & (sub_grupp['P [mm]'] < -P_condition)            \n",
    "        else:\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] < -Q_condition) & (sub_grupp['P [mm]'] < -P_condition)\n",
    "\n",
    "    # where both conditions are true\n",
    "    yesgroup = sub_grupp[(sub_grupp['condition'] == True) & (sub_grupp['tolerance_condition'] == True)] \n",
    "       \n",
    "    \n",
    "    if len(yesgroup) == 0:\n",
    "        print('No data where conditions are met')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    #the first instance where conditions are false after conditions hev been met \n",
    "    nogroup = sub_grupp[(sub_grupp['condition'] == False) | (sub_grupp['tolerance_condition'] == False)]  \n",
    "    \n",
    "    if len(nogroup) == 0:\n",
    "        print('nogroup = 0')\n",
    "        return sub_grupp.loc[yesgroup.index[0]:]\n",
    "\n",
    "    if yesgroup.index[0] < nogroup.index[0]:\n",
    "        print('everything is fine')\n",
    "        return sub_grupp.loc[:nogroup.index[0]]\n",
    "    \n",
    "    else:\n",
    "        print('No valid range found between yesgroup and nogroup indices')\n",
    "        return pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04c2d444-ae00-4668-a2ea-b77826c40347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>wetdry</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>imagery</th>\n",
       "      <th>assumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [geometry, wetdry, x, y, imagery, assumption]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gdf['geometry_wkt'] = gdf['geometry'].apply(lambda geom: geom.wkt)\n",
    "# assuming perennial reaches\n",
    "perennial = pd.DataFrame(gdf.groupby('geometry')['wetdry'].apply(lambda x: sum(x == 'wet'))).reset_index(drop=False)\n",
    "perennialcount = pd.DataFrame(gdf.groupby('geometry')['wetdry'].count()).reset_index(drop=False)\n",
    "\n",
    "# whichever number is reasonable based on data?\n",
    "perennial = perennial[(perennial['wetdry'] >= (perennialcount['wetdry']))]\n",
    "\n",
    "#assume always wet\n",
    "perennial = perennial.assign(wetdry = 'wet')\n",
    "#perennial['geometry'] = perennial['geometry_wkt'].apply(wkt.loads)\n",
    "#perennial = perennial.drop(columns=['geometry_wkt'])\n",
    "\n",
    "#perennial['geometry'] = perennial['geometry'].apply(wkt.loads)\n",
    "gdf_perennial = gpd.GeoDataFrame(perennial, geometry = 'geometry')#, crs='EPSG:26912')\n",
    "gdf_perennial['x'] = gdf_perennial.geometry.x\n",
    "gdf_perennial['y'] = gdf_perennial.geometry.y\n",
    "\n",
    "#making the gdf matching the perennial reaches to all the imagery dates available \n",
    "imagery_perennial = pd.concat([gdf_perennial.assign(imagery = date) for date in C_im_date['date']], ignore_index=True)\n",
    "imagery_perennial = imagery_perennial[~imagery_perennial['imagery'].isin(Ch['Imagery'])]\n",
    "imagery_perennial['assumption'] = len(imagery_perennial)*['assumed perennial']\n",
    "imagery_perennial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4872e688-f795-4a79-b427-cd8b2a6a2d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No valid range found between yesgroup and nogroup indices\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2017-09-19\n",
      "everything is fine\n",
      "No data for date 2016-06-03\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2018-03-23\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2016-09-23\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2017-03-16\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2017-06-09\n",
      "everything is fine\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2018-06-05\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No valid range found between yesgroup and nogroup indices\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2020-09-17\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2022-12-15\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No valid range found between yesgroup and nogroup indices\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2017-12-08\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2019-09-13\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2016-03-18\n",
      "everything is fine\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n"
     ]
    }
   ],
   "source": [
    "#assuming wet stretches for the dates before\n",
    "#assumption is made with 5 % difference in streamflow and for dates before survey when in a recession \n",
    "\n",
    "wet_list = []\n",
    "\n",
    "for date in C_surveyData['Year'].unique():\n",
    "            \n",
    "    wet1 = tolerance(C_new_hyd, 'datetime', date, 'end', 0.05, Q_condition = -999, P_condition = -1)\n",
    "    if len(wet1) == 0:\n",
    "        print('wet1 is empty')\n",
    "        continue\n",
    "    wet1 = wet1[~wet1['datetime'].isin(Ch['Imagery'])]\n",
    "    wet_imagery = pd.merge(wet1, C_im_date, left_on = ['datetime'], right_on = ['date'], how = 'inner')\n",
    "    #print(len(wet_imagery))\n",
    "    wet_points = pd.DataFrame(gdf[gdf['Year']== (date)].groupby('geometry')['wetdry'].apply(lambda x: sum(x == 'wet'))).reset_index(drop = False)\n",
    "    wet_points = wet_points[(wet_points['wetdry'] == 1)]\n",
    "    wet_points = wet_points.assign(wetdry = 'wet')\n",
    "    wet_im_points = [wet_points.assign(imagery = date) for date in wet_imagery['date']]\n",
    "        \n",
    "    try:\n",
    "        wet = pd.concat(wet_im_points).drop(columns = ['level_1'])\n",
    "        wet_list.append(wet)\n",
    "    except:\n",
    "        if len(wet_im_points)==0:\n",
    "            print('No data for date '+ date.strftime('%Y-%m-%d'))\n",
    "        else:\n",
    "            wet = wet_im_points[0]\n",
    "            wet_list.append(wet)\n",
    "        \n",
    "\n",
    "wet_df = pd.concat(wet_list)\n",
    "\n",
    "\n",
    "wet_df['assumption'] = len(wet_df)*['assumed wet']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e5e5c33-8b17-4ce7-ba72-25c2674500fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything is fine\n",
      "No data for date 2004-06-25\n",
      "everything is fine\n",
      "No data for date 2022-09-08\n",
      "everything is fine\n",
      "No data for date 2012-12-12\n",
      "everything is fine\n",
      "No valid range found between yesgroup and nogroup indices\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2008-09-16\n",
      "everything is fine\n",
      "No data for date 2010-06-17\n",
      "everything is fine\n",
      "No data for date 2014-06-13\n",
      "everything is fine\n",
      "No data for date 2005-06-23\n",
      "everything is fine\n",
      "No data for date 2009-06-11\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2011-03-31\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2016-06-03\n",
      "everything is fine\n",
      "No data for date 2004-03-03\n",
      "everything is fine\n",
      "No data for date 2001-06-26\n",
      "everything is fine\n",
      "No data for date 2018-03-23\n",
      "everything is fine\n",
      "No data for date 2010-03-25\n",
      "everything is fine\n",
      "No data for date 2011-12-23\n",
      "everything is fine\n",
      "No data for date 2012-03-13\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2010-12-14\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2016-09-23\n",
      "everything is fine\n",
      "No data for date 2003-09-17\n",
      "everything is fine\n",
      "No data for date 2005-09-28\n",
      "everything is fine\n",
      "No data for date 2008-12-09\n",
      "everything is fine\n",
      "No data for date 2006-09-09\n",
      "everything is fine\n",
      "No data for date 2008-03-18\n",
      "everything is fine\n",
      "No data for date 2017-03-16\n",
      "everything is fine\n",
      "No data for date 2002-03-22\n",
      "everything is fine\n",
      "No data for date 2013-12-04\n",
      "everything is fine\n",
      "No data for date 2007-06-15\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2005-12-21\n",
      "everything is fine\n",
      "No data for date 2003-12-19\n",
      "everything is fine\n",
      "No data for date 2003-03-25\n",
      "everything is fine\n",
      "No data for date 2001-12-14\n",
      "everything is fine\n",
      "No data for date 2000-06-01\n",
      "everything is fine\n",
      "No data for date 2017-06-09\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2007-12-18\n",
      "everything is fine\n",
      "No data for date 2015-12-09\n",
      "everything is fine\n",
      "No data for date 2013-03-27\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2004-12-22\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2014-12-12\n",
      "everything is fine\n",
      "No data for date 2022-03-18\n",
      "everything is fine\n",
      "No data for date 2013-06-12\n",
      "everything is fine\n",
      "No data for date 2007-09-27\n",
      "No valid range found between yesgroup and nogroup indices\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2001-09-18\n",
      "everything is fine\n",
      "No data for date 2006-06-26\n",
      "everything is fine\n",
      "No data for date 2012-06-14\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2006-03-31\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2007-03-14\n",
      "everything is fine\n",
      "No data for date 2006-12-15\n",
      "No valid range found between yesgroup and nogroup indices\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2002-06-19\n",
      "everything is fine\n",
      "No data for date 2003-06-03\n",
      "everything is fine\n",
      "No data for date 2015-06-16\n",
      "everything is fine\n",
      "No data for date 2015-09-16\n",
      "everything is fine\n",
      "No data for date 2014-09-26\n",
      "everything is fine\n",
      "No data for date 2009-12-07\n",
      "everything is fine\n",
      "No data for date 2002-09-19\n",
      "everything is fine\n",
      "No data for date 2019-09-13\n",
      "everything is fine\n",
      "No data for date 2015-03-13\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2008-06-12\n",
      "everything is fine\n",
      "No data for date 2016-03-18\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2005-04-14\n",
      "everything is fine\n",
      "No data for date 2011-09-22\n",
      "everything is fine\n",
      "No data for date 2004-10-08\n",
      "everything is fine\n",
      "No data for date 2014-03-13\n",
      "everything is fine\n",
      "No data for date 2009-09-23\n",
      "everything is fine\n",
      "No data for date 2009-03-04\n",
      "everything is fine\n",
      "No data for date 2002-12-17\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2012-09-18\n",
      "everything is fine\n",
      "No data for date 2010-09-09\n",
      "everything is fine\n",
      "No data for date 2011-06-08\n",
      "everything is fine\n",
      "No data for date 2013-09-05\n"
     ]
    }
   ],
   "source": [
    "#assuming dry stretches for the dates after\n",
    "#assumption is made with 5 % difference in streamflow and for dates after survey when in a recession \n",
    "\n",
    "dry_list = []\n",
    "\n",
    "\n",
    "for date in C_surveyData['Year'].unique():\n",
    "            \n",
    "    dry1 = tolerance(C_new_hyd, 'datetime', date, 'start', 0.05, Q_condition = -999, P_condition = -1)\n",
    "    if len(dry1) == 0:\n",
    "        print('wet1 is empty')\n",
    "        continue\n",
    "    dry1 = dry1[~dry1['datetime'].isin(Ch['Imagery'])]\n",
    "    dry_imagery = pd.merge(dry1, C_im_date, left_on = ['datetime'], right_on = ['date'], how = 'inner')\n",
    "        #print(len(wet_imagery))\n",
    "    dry_points = pd.DataFrame(gdf[gdf['Year']== (date)].groupby('geometry')['wetdry'].apply(lambda x: sum(x == 'dry'))).reset_index(drop = False)\n",
    "    dry_points = dry_points[(dry_points['wetdry'] == 1)].assign(wetdry = 'dry')\n",
    "    dry_im_points = [dry_points.assign(imagery = date) for date in dry_imagery['date']]\n",
    "        \n",
    "    try:\n",
    "        dry = pd.concat(dry_im_points).drop(columns = ['level_1'])\n",
    "        dry_list.append(dry)\n",
    "        \n",
    "    except:\n",
    "        if len(dry_im_points)==0:\n",
    "            print('No data for date '+ date.strftime('%Y-%m-%d'))\n",
    "        else:\n",
    "            dry = dry_im_points[0]\n",
    "            dry_list.append(dry)\n",
    "        #print(len(dry))\n",
    "        \n",
    "\n",
    "dry_df = pd.concat(dry_list)\n",
    "\n",
    "dry_df['assumption'] = len(dry_df)*['assumed dry']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a74226f7-cd05-4586-ae77-c66bd71a61ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>wetdry</th>\n",
       "      <th>assumption</th>\n",
       "      <th>Imagery</th>\n",
       "      <th>date_first</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (533719.252 3542427.373)</td>\n",
       "      <td>533719.252411</td>\n",
       "      <td>3.542427e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (533719.787 3542422.402)</td>\n",
       "      <td>533719.786671</td>\n",
       "      <td>3.542422e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (533720.321 3542417.431)</td>\n",
       "      <td>533720.320931</td>\n",
       "      <td>3.542417e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (533720.855 3542412.459)</td>\n",
       "      <td>533720.855191</td>\n",
       "      <td>3.542412e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (533721.389 3542407.488)</td>\n",
       "      <td>533721.389451</td>\n",
       "      <td>3.542407e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>POINT (539511.378 3540289.598)</td>\n",
       "      <td>539511.377590</td>\n",
       "      <td>3.540290e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>assumed dry</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-09-09</td>\n",
       "      <td>2018-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>POINT (539516.317 3540290.375)</td>\n",
       "      <td>539516.316935</td>\n",
       "      <td>3.540290e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>assumed dry</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-09-09</td>\n",
       "      <td>2018-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>POINT (539396.748 3540256.611)</td>\n",
       "      <td>539396.747956</td>\n",
       "      <td>3.540257e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>assumed dry</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-09-09</td>\n",
       "      <td>2018-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>POINT (539392.098 3540254.772)</td>\n",
       "      <td>539392.098410</td>\n",
       "      <td>3.540255e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>assumed dry</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-09-09</td>\n",
       "      <td>2018-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>POINT (539387.449 3540252.933)</td>\n",
       "      <td>539387.448864</td>\n",
       "      <td>3.540253e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>assumed dry</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2018-09-09</td>\n",
       "      <td>2018-09-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280803 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            geometry              x             y wetdry  \\\n",
       "0     POINT (533719.252 3542427.373)  533719.252411  3.542427e+06    dry   \n",
       "1     POINT (533719.787 3542422.402)  533719.786671  3.542422e+06    dry   \n",
       "2     POINT (533720.321 3542417.431)  533720.320931  3.542417e+06    dry   \n",
       "3     POINT (533720.855 3542412.459)  533720.855191  3.542412e+06    dry   \n",
       "4     POINT (533721.389 3542407.488)  533721.389451  3.542407e+06    dry   \n",
       "...                              ...            ...           ...    ...   \n",
       "2636  POINT (539511.378 3540289.598)  539511.377590  3.540290e+06    dry   \n",
       "2637  POINT (539516.317 3540290.375)  539516.316935  3.540290e+06    dry   \n",
       "2638  POINT (539396.748 3540256.611)  539396.747956  3.540257e+06    dry   \n",
       "2639  POINT (539392.098 3540254.772)  539392.098410  3.540255e+06    dry   \n",
       "2640  POINT (539387.449 3540252.933)  539387.448864  3.540253e+06    dry   \n",
       "\n",
       "                assumption Imagery date_first       date  \n",
       "0     survey/imagery match     NaT        NaT        NaT  \n",
       "1     survey/imagery match     NaT        NaT        NaT  \n",
       "2     survey/imagery match     NaT        NaT        NaT  \n",
       "3     survey/imagery match     NaT        NaT        NaT  \n",
       "4     survey/imagery match     NaT        NaT        NaT  \n",
       "...                    ...     ...        ...        ...  \n",
       "2636           assumed dry     NaT 2018-09-09 2018-09-09  \n",
       "2637           assumed dry     NaT 2018-09-09 2018-09-09  \n",
       "2638           assumed dry     NaT 2018-09-09 2018-09-09  \n",
       "2639           assumed dry     NaT 2018-09-09 2018-09-09  \n",
       "2640           assumed dry     NaT 2018-09-09 2018-09-09  \n",
       "\n",
       "[280803 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate all dfs with assumptions and survey matched to imagery dates and turn to gdf\n",
    "gdf['assumption'] = len(gdf)*['survey/imagery match']\n",
    "gdf_imagery = pd.merge(gdf, Ch, left_on = 'Year', right_on = 'Survey', how = 'left')\n",
    "gdf_imagery = gdf_imagery.drop(columns=['Survey', 'sum_P', 'Q_diff [%]', 'Year'])\n",
    "all_expanded = pd.concat([gdf_imagery, imagery_perennial, wet_df, dry_df])\n",
    "all_expanded = gpd.GeoDataFrame(all_expanded, geometry = 'geometry')#, crs='EPSG:26912')\n",
    "all_expanded['x'] = all_expanded.geometry.x\n",
    "all_expanded['y'] = all_expanded.geometry.y\n",
    "all_expanded = all_expanded.rename(columns = {'imagery':'date_first'})\n",
    "all_expanded['date'] = all_expanded['Imagery'].combine_first(all_expanded['date_first'])\n",
    "all_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8449ef5-28ea-4775-89aa-fa061a7c64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading and concatenating the processed imagery \n",
    "path = '../data/Cienega/processed_imagery'\n",
    "\n",
    "processed_imagery = glob.glob(path + '/*.csv')\n",
    "processed_imagery.sort(key = lambda x: int(x.split('_buffer_')[1].split('.')[0]))\n",
    "con_ready_imagery = []\n",
    "for processed in processed_imagery:\n",
    "    df= pd.read_csv(processed)\n",
    "    con_ready_imagery.append(df)\n",
    "\n",
    "concatenated = pd.concat(con_ready_imagery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8e02208-2077-4fef-a1e0-6bd15b6c1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated['geometry'] = concatenated['geometry'].apply(wkt.loads)\n",
    "gdf_processed = gpd.GeoDataFrame(concatenated, geometry = 'geometry')#, crs='EPSG:26912')\n",
    "gdf_processed['date'] = pd.to_datetime(gdf_processed['date'], format='%Y%m%d')\n",
    "gdf_processed['x'] = gdf_processed.geometry.x\n",
    "gdf_processed['y'] = gdf_processed.geometry.y\n",
    "gdf_processed = gdf_processed.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4264da09-bd77-43ca-bb2d-745ea3af7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 6\n",
    "all_expanded['x'] = all_expanded['x'].round(precision)\n",
    "all_expanded['y'] = all_expanded['y'].round(precision)\n",
    "gdf_processed['x'] = gdf_processed['x'].round(precision)\n",
    "gdf_processed['y'] = gdf_processed['y'].round(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f609f457-9b11-4a8b-aa11-2c9177bd3578",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = all_expanded.merge(gdf_processed, on=['date', 'x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "448f9ab5-691c-4e20-8ce2-80d629ba6f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>wetdry</th>\n",
       "      <th>assumption</th>\n",
       "      <th>date</th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "      <th>NIR</th>\n",
       "      <th>missing</th>\n",
       "      <th>NDWI</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67535</th>\n",
       "      <td>534451.929516</td>\n",
       "      <td>3.542234e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>1124.56</td>\n",
       "      <td>1395.33</td>\n",
       "      <td>1837.78</td>\n",
       "      <td>2920.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67533</th>\n",
       "      <td>534446.929543</td>\n",
       "      <td>3.542234e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>1089.56</td>\n",
       "      <td>1368.11</td>\n",
       "      <td>1801.33</td>\n",
       "      <td>2846.22</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67531</th>\n",
       "      <td>534441.929569</td>\n",
       "      <td>3.542234e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>1073.56</td>\n",
       "      <td>1343.22</td>\n",
       "      <td>1780.00</td>\n",
       "      <td>2792.22</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67537</th>\n",
       "      <td>534455.700434</td>\n",
       "      <td>3.542231e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>944.22</td>\n",
       "      <td>1228.11</td>\n",
       "      <td>1619.22</td>\n",
       "      <td>2888.56</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67529</th>\n",
       "      <td>534436.929596</td>\n",
       "      <td>3.542234e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>survey/imagery match</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>997.56</td>\n",
       "      <td>1270.00</td>\n",
       "      <td>1691.44</td>\n",
       "      <td>2742.11</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222793</th>\n",
       "      <td>532264.228957</td>\n",
       "      <td>3.543183e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>assumed dry</td>\n",
       "      <td>2023-06-11</td>\n",
       "      <td>1069.11</td>\n",
       "      <td>1500.78</td>\n",
       "      <td>1842.22</td>\n",
       "      <td>2806.89</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222791</th>\n",
       "      <td>532265.567543</td>\n",
       "      <td>3.543178e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>assumed dry</td>\n",
       "      <td>2023-06-11</td>\n",
       "      <td>1065.11</td>\n",
       "      <td>1512.44</td>\n",
       "      <td>1836.00</td>\n",
       "      <td>2769.11</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222789</th>\n",
       "      <td>532266.906128</td>\n",
       "      <td>3.543173e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>assumed dry</td>\n",
       "      <td>2023-06-11</td>\n",
       "      <td>1076.78</td>\n",
       "      <td>1495.44</td>\n",
       "      <td>1825.89</td>\n",
       "      <td>2851.56</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222787</th>\n",
       "      <td>532262.890372</td>\n",
       "      <td>3.543187e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>assumed dry</td>\n",
       "      <td>2023-06-11</td>\n",
       "      <td>1094.89</td>\n",
       "      <td>1502.78</td>\n",
       "      <td>1848.11</td>\n",
       "      <td>2786.89</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222785</th>\n",
       "      <td>532261.551787</td>\n",
       "      <td>3.543192e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>assumed dry</td>\n",
       "      <td>2023-06-11</td>\n",
       "      <td>1054.56</td>\n",
       "      <td>1459.89</td>\n",
       "      <td>1803.00</td>\n",
       "      <td>2797.44</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213380 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    x             y wetdry            assumption       date  \\\n",
       "67535   534451.929516  3.542234e+06    dry  survey/imagery match 2016-09-22   \n",
       "67533   534446.929543  3.542234e+06    dry  survey/imagery match 2016-09-22   \n",
       "67531   534441.929569  3.542234e+06    dry  survey/imagery match 2016-09-22   \n",
       "67537   534455.700434  3.542231e+06    dry  survey/imagery match 2016-09-22   \n",
       "67529   534436.929596  3.542234e+06    dry  survey/imagery match 2016-09-22   \n",
       "...               ...           ...    ...                   ...        ...   \n",
       "222793  532264.228957  3.543183e+06    dry           assumed dry 2023-06-11   \n",
       "222791  532265.567543  3.543178e+06    dry           assumed dry 2023-06-11   \n",
       "222789  532266.906128  3.543173e+06    dry           assumed dry 2023-06-11   \n",
       "222787  532262.890372  3.543187e+06    dry           assumed dry 2023-06-11   \n",
       "222785  532261.551787  3.543192e+06    dry           assumed dry 2023-06-11   \n",
       "\n",
       "           blue    green      red      NIR  missing  NDWI  p  \n",
       "67535   1124.56  1395.33  1837.78  2920.00        0 -0.35  0  \n",
       "67533   1089.56  1368.11  1801.33  2846.22        0 -0.35  0  \n",
       "67531   1073.56  1343.22  1780.00  2792.22        0 -0.35  0  \n",
       "67537    944.22  1228.11  1619.22  2888.56        0 -0.40  0  \n",
       "67529    997.56  1270.00  1691.44  2742.11        0 -0.37  0  \n",
       "...         ...      ...      ...      ...      ...   ... ..  \n",
       "222793  1069.11  1500.78  1842.22  2806.89        0 -0.30  0  \n",
       "222791  1065.11  1512.44  1836.00  2769.11        0 -0.29  0  \n",
       "222789  1076.78  1495.44  1825.89  2851.56        0 -0.31  0  \n",
       "222787  1094.89  1502.78  1848.11  2786.89        0 -0.30  0  \n",
       "222785  1054.56  1459.89  1803.00  2797.44        0 -0.31  0  \n",
       "\n",
       "[213380 rows x 12 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = merged.drop(columns = ['geometry_x', 'geometry_y', 'Imagery', 'date_first']) \n",
    "merged_sorted = merged.sort_values(by='date')\n",
    "merged_sorted = merged_sorted.drop_duplicates()\n",
    "merged_sorted.dropna(inplace= True)\n",
    "merged_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "482dd362-9c0c-4157-a19c-79cccbaee270",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "splitnum = 10\n",
    "for i in range(1,splitnum+1):\n",
    "    newstart = int(len(merged_sorted)/splitnum*i)\n",
    "    merged_sorted.iloc[start:newstart].to_csv('../data/Cienega/processed_assumptions/processed_with_dates_and_assumptions'+str(i)+'.csv',index=False,\n",
    "                      float_format='%.2f')\n",
    "    start = newstart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000cf055-8029-4d76-a6d5-65a3d1b956c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452e608-c3ce-4b94-a3f8-a24e228ff95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6bf3f9-ba52-45bc-be7c-6f9368ec2451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
