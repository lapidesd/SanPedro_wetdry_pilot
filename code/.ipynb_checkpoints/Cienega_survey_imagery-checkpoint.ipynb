{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0714e9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m \n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m timedelta\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Point\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv \n",
    "import geopandas as gpd\n",
    "from datetime import timedelta\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5fa590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv files and adjust to datetime\n",
    "C_im_date = pd.read_csv('../data/Cienega/CienegaImageryDates.csv', parse_dates=['date'])\n",
    "C_sur_date = pd.read_csv('../data/Cienega/Cienega_survey_dates.csv', parse_dates=['Cienega date'])\n",
    "C_sur_date['Cienega date'] = pd.to_datetime(C_sur_date['Cienega date'])\n",
    "C_im_date['date'] = pd.to_datetime(C_im_date['date'])\n",
    "\n",
    "C_hyd = pd.read_csv('../data/Cienega/CienegaHydroData.csv')\n",
    "C_hyd['datetime'] = pd.to_datetime(C_hyd['datetime'])\n",
    "\n",
    "C_precipitation = pd.read_csv('../data/Cienega/daymet_precip.csv')\n",
    "C_precipitation['system:time_start'] = pd.to_datetime(C_precipitation['system:time_start'])\n",
    "C_precipitation.rename( columns={'00000000000000000000':'P','system:time_start':'day'}, inplace=True )\n",
    "\n",
    "C_sur_date = C_sur_date.dropna(subset=['Cienega date'])\n",
    "C_im_date = C_im_date.dropna(subset=['date'])\n",
    "\n",
    "C_surveyData = pd.read_csv('../data/Cienega/Cienega_surveyData.csv')\n",
    "C_surveyData['Year'] = pd.to_datetime(C_surveyData['Year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e40101-6840-4b66-9463-fe3836524a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding closest matching dates between survey and imagery\n",
    "matching_dates = []\n",
    "tolerance = timedelta(days = 5)\n",
    "\n",
    "\n",
    "for date1 in C_sur_date['Cienega date']:\n",
    "    exact_date = False\n",
    "    tol = False \n",
    "    for date2 in C_im_date['date']:\n",
    "        if date1 == date2:\n",
    "            matching_dates.append({'Survey': date1, 'Imagery': date2})\n",
    "            exact_date = True\n",
    "    if not exact_date:\n",
    "        for date2 in C_im_date['date']:\n",
    "            if abs(date1 - date2) <= tolerance:\n",
    "                matching_dates.append({'Survey': date1, 'Imagery': date2})\n",
    "                tol = True\n",
    "        if not tol:\n",
    "            for date2 in C_im_date['date']:\n",
    "                if abs(date1-date2) < timedelta(days = 10): \n",
    "                    matching_dates.append({'Survey': date1, 'Imagery': date2})\n",
    "\n",
    "\n",
    "matching_dates_df = pd.DataFrame(matching_dates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fcdb11-21ef-486c-9453-2c804317ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging dfs to use to determine imagery dates for survey dates\n",
    "C_datessurData = pd.merge(matching_dates_df, C_hyd, left_on = 'Survey', right_on = 'datetime', how = 'left')\n",
    "C_datesimData = pd.merge(matching_dates_df, C_hyd, left_on = 'Imagery', right_on = 'datetime')\n",
    "C_datessurData = C_datessurData.drop(columns = ['Imagery','datetime'])\n",
    "C_datesimData = C_datesimData.drop(columns = ['Survey','datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b120b39f-b3a4-496f-a222-d238759841c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum precipitation for dates in between survey and imagery\n",
    "def sum_pdatesbetween(d1, d2):\n",
    "    r = pd.date_range(start=min(d1,d2), end=max(d1,d2))\n",
    "    return C_hyd[C_hyd['datetime'].isin(r)]['P [mm]'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e5aee-1bfa-41a2-a45d-7a31efc27e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe to determine which imagery dates to use\n",
    "Ch = pd.DataFrame([])\n",
    "\n",
    "Ch['Survey'] = matching_dates_df['Survey']\n",
    "Ch['Imagery'] = matching_dates_df['Imagery']\n",
    "Ch['sum_P'] = [sum_pdatesbetween(C_datessurData.loc[i, 'Survey'], C_datesimData.loc[i, 'Imagery']) for i in range(len(Ch))]\n",
    "Ch['Q_diff [%]'] = (C_datessurData['Q [mm/d]'] - C_datesimData['Q [mm/d]']) / C_datessurData['Q [mm/d]'] * 100\n",
    "Ch['Use/not'] = ['use', 'use', 'use', 'use', 'not', 'not', 'use?',\n",
    "                 'not', 'only option', 'not', 'not', 'use', 'not',\n",
    "                 'not', 'not', 'use', 'not', 'not', 'not', 'not',\n",
    "                 'use', 'use', 'use', 'only option','use', 'use', \n",
    "                 'use','use', 'not', 'not', 'not', 'not', 'use', \n",
    "                 'not', 'use', 'use', 'use', 'use', 'use', 'not', \n",
    "                 'not', 'not', 'not', 'use', 'not', 'not', 'not', \n",
    "                 'not', 'not', 'use', 'not', 'not', 'not', 'use', \n",
    "                 'not', 'use', 'use']\n",
    "\n",
    "\n",
    "conditions = (Ch['sum_P'] > 3) | (Ch['Q_diff [%]'] > 8) | (Ch['Use/not'] == 'not')\n",
    "\n",
    "Ch = Ch[~conditions]\n",
    "\n",
    "Ch = Ch.drop(columns=['Use/not'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d3a2e6-c9cf-4106-b335-dbf5ad595f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ch.to_csv('../data/Cienega/Cienega_survey_imagery_HydroData.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeeeb2b-6f94-4b55-8f30-f6c4c0243bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e49da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading surveydata, making it into a geodataframe and adding x and y from the geometry to facilitate merge later \n",
    "C_surveyData['geometry'] = C_surveyData['geometry'].apply(wkt.loads)\n",
    "gdf = gpd.GeoDataFrame(C_surveyData, geometry = 'geometry', crs='EPSG:26912')\n",
    "gdf['x'] = gdf.geometry.x\n",
    "gdf['y'] = gdf.geometry.y\n",
    "gdf = gdf[['geometry', 'x', 'y', 'wetdry', 'Year']]\n",
    "gdf['Year'] = pd.to_datetime(gdf['Year'])\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb368f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using new data for precipitation \n",
    "C_new_hyd = C_hyd.merge(C_precipitation, left_on = 'datetime', right_on = 'day')\n",
    "C_new_hyd = C_new_hyd.drop(columns = ['day', 'P [mm]'])\n",
    "C_new_hyd.rename( columns={'P':'P [mm]'}, inplace=True )\n",
    "C_new_hyd.set_index(['datetime'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4057a74-ca6f-4dcc-936f-e46986f528f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to define assumptions around dates to choose, based on streamflow and precipitation\n",
    "# Q_condition could be completely removed\n",
    "def tolerance(Q_P_data, date, start, adjust, tolerance_p, P_condition = -999, Q_condition = -999):\n",
    "    \n",
    "    sub_grupp = Q_P_data.copy()\n",
    "    \n",
    "    if adjust == 'start':      \n",
    "        sub_grupp = Q_P_data.loc[start:].copy()       \n",
    "        \n",
    "    elif adjust == 'end': #reverse index to loop backwards\n",
    "        sub_grupp = sub_grupp.loc[:start].copy().iloc[::-1]        \n",
    "    \n",
    "    else:\n",
    "        print('Invalid adjust parameter. Please use \"start\" or \"end\"')\n",
    "        return\n",
    "\n",
    "    \n",
    "    # Reset index if reversed\n",
    "    sub_grupp.reset_index(inplace=True)\n",
    "\n",
    "    #creating a column for difference in streamflow\n",
    "    sub_grupp['Q_diff'] = sub_grupp['Q [mm/d]'].diff().fillna(0)\n",
    "\n",
    "    #checking to see if streamflow is overall decreasing, but a tolerance of x for any daily increase\n",
    "    if adjust == 'start':\n",
    "        sub_grupp['tolerance_condition'] = (sub_grupp.Q_diff < tolerance_p * sub_grupp['Q [mm/d]'])\n",
    "\n",
    "    if adjust == 'end':\n",
    "        sub_grupp['tolerance_condition'] = (sub_grupp.Q_diff > -tolerance_p * sub_grupp['Q [mm/d]'])\n",
    "\n",
    "    \n",
    "    if P_condition == -999 == Q_condition:\n",
    "        print('not a valid condition')\n",
    "        return \n",
    "        \n",
    "    elif P_condition == -999:\n",
    "        if Q_condition > 0:\n",
    "            sub_grupp['condition'] = sub_grupp['Q [mm/d]'] > Q_condition\n",
    "        else:\n",
    "            sub_grupp['condition'] = sub_grupp['Q [mm/d]'] < -Q_condition\n",
    "            \n",
    "    elif Q_condition == -999:\n",
    "        if P_condition > 0:\n",
    "            sub_grupp['condition'] = sub_grupp['P [mm]'] > P_condition\n",
    "        else:\n",
    "            sub_grupp['condition'] = sub_grupp['P [mm]'] < -P_condition\n",
    "            \n",
    "    else:\n",
    "        if (Q_condition > 0) & (P_condition > 0):\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] > Q_condition) & (sub_grupp['P [mm]'] > P_condition)\n",
    "        elif (Q_condition < 0) & (P_condition > 0):\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] < -Q_condition) & (sub_grupp['P [mm]'] > P_condition)           \n",
    "        elif (Q_condition > 0) & (P_condition < 0):\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] > Q_condition) & (sub_grupp['P [mm]'] < -P_condition)            \n",
    "        else:\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] < -Q_condition) & (sub_grupp['P [mm]'] < -P_condition)\n",
    "\n",
    "    # where both conditions are true\n",
    "    yesgroup = sub_grupp[(sub_grupp['condition'] == True) & (sub_grupp['tolerance_condition'] == True)] \n",
    "       \n",
    "    \n",
    "    if len(yesgroup) == 0:\n",
    "        print('No data where conditions are met')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    #the first instance where conditions are false after conditions hev been met \n",
    "    nogroup = sub_grupp[(sub_grupp['condition'] == False) | (sub_grupp['tolerance_condition'] == False)]  \n",
    "    \n",
    "    if len(nogroup) == 0:\n",
    "        print('nogroup = 0')\n",
    "        return sub_grupp.loc[yesgroup.index[0]:]\n",
    "\n",
    "    if yesgroup.index[0] < nogroup.index[0]:\n",
    "        print('everything is fine')\n",
    "        return sub_grupp.loc[:nogroup.index[0]]\n",
    "    \n",
    "    else:\n",
    "        print('No valid range found between yesgroup and nogroup indices')\n",
    "        return pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62cc9b4-5bf8-4113-a61c-e595d7d220f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming perennial reaches\n",
    "perennial = pd.DataFrame(gdf.groupby('geometry')['wetdry'].apply(lambda x: sum(x == 'wet'))).reset_index(drop=False)\n",
    "perennialcount = pd.DataFrame(gdf.groupby('geometry')['wetdry'].count()).reset_index(drop=False)\n",
    "\n",
    "# whichever number is reasonable based on data?\n",
    "perennial = perennial[(perennial['wetdry'] >= (perennialcount['wetdry']))]\n",
    "\n",
    "#assume always wet\n",
    "perennial = perennial.assign(wetdry = 'wet')\n",
    "\n",
    "#perennial['geometry'] = perennial['geometry'].apply(wkt.loads)\n",
    "gdf_perennial = gpd.GeoDataFrame(perennial, geometry = 'geometry', crs='EPSG:26912')\n",
    "gdf_perennial['x'] = gdf_perennial.geometry.x\n",
    "gdf_perennial['y'] = gdf_perennial.geometry.y\n",
    "\n",
    "#making the gdf matching the perennial reaches to all the imagery dates available \n",
    "imagery_perennial = pd.concat([gdf_perennial.assign(imagery = date) for date in C_im_date['date']], ignore_index=True)\n",
    "imagery_perennial = imagery_perennial[~imagery_perennial['imagery'].isin(Ch['Imagery'])]\n",
    "imagery_perennial['assumption'] = len(imagery_perennial)*['assumed perennial']\n",
    "imagery_perennial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c2d444-ae00-4668-a2ea-b77826c40347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assuming wet stretches for the dates before\n",
    "#assumption is made with 5 % difference in streamflow and for dates before survey when in a recession \n",
    "\n",
    "wet_list = []\n",
    "\n",
    "for date in C_surveyData['Year'].unique():\n",
    "            \n",
    "    wet1 = tolerance(C_new_hyd, 'datetime', date, 'end', 0.05, Q_condition = -999, P_condition = -1)\n",
    "    if len(wet1) == 0:\n",
    "        print('wet1 is empty')\n",
    "        continue\n",
    "    wet1 = wet1[~wet1['datetime'].isin(Ch['Imagery'])]\n",
    "    wet_imagery = pd.merge(wet1, C_im_date, left_on = ['datetime'], right_on = ['date'], how = 'inner')\n",
    "    #print(len(wet_imagery))\n",
    "    wet_points = pd.DataFrame(gdf[gdf['Year']== (date)].groupby('geometry')['wetdry'].apply(lambda x: sum(x == 'wet'))).reset_index(drop = False)\n",
    "    wet_points = wet_points[(wet_points['wetdry'] == 1)]\n",
    "    wet_points = wet_points.assign(wetdry = 'wet')\n",
    "    wet_im_points = [wet_points.assign(imagery = date) for date in wet_imagery['date']]\n",
    "        \n",
    "    try:\n",
    "        wet = pd.concat(wet_im_points).drop(columns = ['level_1'])\n",
    "        wet_list.append(wet)\n",
    "    except:\n",
    "        if len(wet_im_points)==0:\n",
    "            print('No data for date '+ date.strftime('%Y-%m-%d'))\n",
    "        else:\n",
    "            wet = wet_im_points[0]\n",
    "            wet_list.append(wet)\n",
    "        \n",
    "\n",
    "wet_df = pd.concat(wet_list)\n",
    "\n",
    "\n",
    "wet_df['assumption'] = len(wet_df)*['assumed wet']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4872e688-f795-4a79-b427-cd8b2a6a2d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assuming dry stretches for the dates after\n",
    "#assumption is made with 5 % difference in streamflow and for dates after survey when in a recession \n",
    "\n",
    "dry_list = []\n",
    "\n",
    "\n",
    "for date in C_surveyData['Year'].unique():\n",
    "            \n",
    "    dry1 = tolerance(C_new_hyd, 'datetime', date, 'start', 0.05, Q_condition = -999, P_condition = -1)\n",
    "    if len(dry1) == 0:\n",
    "        print('wet1 is empty')\n",
    "        continue\n",
    "    dry1 = dry1[~dry1['datetime'].isin(Ch['Imagery'])]\n",
    "    dry_imagery = pd.merge(dry1, C_im_date, left_on = ['datetime'], right_on = ['date'], how = 'inner')\n",
    "        #print(len(wet_imagery))\n",
    "    dry_points = pd.DataFrame(gdf[gdf['Year']== (date)].groupby('geometry')['wetdry'].apply(lambda x: sum(x == 'dry'))).reset_index(drop = False)\n",
    "    dry_points = dry_points[(dry_points['wetdry'] == 1)].assign(wetdry = 'dry')\n",
    "    dry_im_points = [dry_points.assign(imagery = date) for date in dry_imagery['date']]\n",
    "        \n",
    "    try:\n",
    "        dry = pd.concat(dry_im_points).drop(columns = ['level_1'])\n",
    "        dry_list.append(dry)\n",
    "        \n",
    "    except:\n",
    "        if len(dry_im_points)==0:\n",
    "            print('No data for date '+ date.strftime('%Y-%m-%d'))\n",
    "        else:\n",
    "            dry = dry_im_points[0]\n",
    "            dry_list.append(dry)\n",
    "        #print(len(dry))\n",
    "        \n",
    "\n",
    "dry_df = pd.concat(dry_list)\n",
    "\n",
    "dry_df['assumption'] = len(dry_df)*['assumed dry']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0d5c99-5dd0-48dd-b13a-00c4e5c0f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all dfs with assumptions and survey matched to imagery dates and turn to gdf\n",
    "gdf['assumption'] = len(gdf)*['survey/imagery match']\n",
    "gdf_imagery = pd.merge(gdf, Ch, left_on = 'Year', right_on = 'Survey', how = 'left')\n",
    "gdf_imagery = gdf_imagery.drop(columns=['Survey', 'sum_P', 'Q_diff [%]', 'Year'])\n",
    "all_expanded = pd.concat([gdf_imagery, imagery_perennial, wet_df, dry_df])\n",
    "all_expanded = gpd.GeoDataFrame(all_expanded, geometry = 'geometry', crs='EPSG:26912')\n",
    "all_expanded['x'] = all_expanded.geometry.x\n",
    "all_expanded['y'] = all_expanded.geometry.y\n",
    "all_expanded = all_expanded.rename(columns = {'imagery':'date_first'})\n",
    "all_expanded['date'] = all_expanded['Imagery'].combine_first(all_expanded['date_first'])\n",
    "all_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8449ef5-28ea-4775-89aa-fa061a7c64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading and concatenating the processed imagery \n",
    "path = '../data/Cienega/processed_imagery'\n",
    "\n",
    "processed_imagery = glob.glob(path + '/*.csv')\n",
    "processed_imagery.sort(key = lambda x: int(x.split('_buffer_')[1].split('.')[0]))\n",
    "con_ready_imagery = []\n",
    "for processed in processed_imagery:\n",
    "    df= pd.read_csv(processed)\n",
    "    con_ready_imagery.append(df)\n",
    "\n",
    "concatenated = pd.concat(con_ready_imagery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e02208-2077-4fef-a1e0-6bd15b6c1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated['geometry'] = concatenated['geometry'].apply(wkt.loads)\n",
    "gdf_processed = gpd.GeoDataFrame(concatenated, geometry = 'geometry', crs='EPSG:26912')\n",
    "gdf_processed['date'] = pd.to_datetime(gdf_processed['date'], format='%Y%m%d')\n",
    "gdf_processed['x'] = gdf_processed.geometry.x\n",
    "gdf_processed['y'] = gdf_processed.geometry.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3ac605-a664-46e3-8f29-dc179047b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf2 = gdf2.drop_duplicates()\n",
    "gdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264da09-bd77-43ca-bb2d-745ea3af7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 6\n",
    "all_expanded['x'] = all_expanded['x'].round(precision)\n",
    "all_expanded['y'] = all_expanded['y'].round(precision)\n",
    "gdf_processed['x'] = gdf_processed['x'].round(precision)\n",
    "gdf_processed['y'] = gdf_processed['y'].round(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be3a98-d7b8-4d51-87b0-bc0de9e9dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = all_expanded.merge(gdf_processed, on=['date', 'x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482dd362-9c0c-4157-a19c-79cccbaee270",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.drop(columns = ['geometry_x', 'geometry_y', 'Imagery', 'date_first']) \n",
    "merged_sorted = merged.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e92102-0f4d-48a4-aee9-099e97f4410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sorted = merged_sorted.drop_duplicates()\n",
    "merged_sorted.dropna(inplace= True)\n",
    "merged_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6c9bd4-783b-41ba-b05c-42cf79881256",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "splitnum = 10\n",
    "for i in range(1,splitnum+1):\n",
    "    newstart = int(len(merged_sorted)/splitnum*i)\n",
    "    merged_sorted.iloc[start:newstart].to_csv('../data/Cienega/processed_assumptions/processed_with_dates_and_assumptions'+str(i)+'.csv',index=False,\n",
    "                      float_format='%.2f')\n",
    "    start = newstart\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d133df9-18c4-4e9c-981d-4964880e9bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b3a0b-8a5e-4568-895d-7862ed075ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f66fc-1c70-4c0a-ab30-a717d68f1fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e46e2e-5118-4db4-b2fd-0e844401787b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bcc12e-fac5-481b-ac05-0922f93cf7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701460e6-268d-4a31-b3f2-125b333b0787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
