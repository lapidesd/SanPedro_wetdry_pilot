{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0714e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv \n",
    "import geopandas as gpd\n",
    "from datetime import timedelta\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed5fa590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv files and adjust to datetime\n",
    "C_im_date = pd.read_csv('../data/Cienega/CienegaImageryDates.csv', parse_dates=['date'])\n",
    "C_sur_date = pd.read_csv('../data/Cienega/Cienega_survey_dates.csv', parse_dates=['Cienega date'])\n",
    "C_sur_date['Cienega date'] = pd.to_datetime(C_sur_date['Cienega date'])\n",
    "C_im_date['date'] = pd.to_datetime(C_im_date['date'])\n",
    "\n",
    "C_hyd = pd.read_csv('../data/Cienega/CienegaHydroData.csv')\n",
    "C_hyd['datetime'] = pd.to_datetime(C_hyd['datetime'])\n",
    "\n",
    "C_precipitation = pd.read_csv('../data/Cienega/daymet_precip.csv')\n",
    "C_precipitation['system:time_start'] = pd.to_datetime(C_precipitation['system:time_start'])\n",
    "C_precipitation.rename( columns={'00000000000000000000':'P','system:time_start':'day'}, inplace=True )\n",
    "\n",
    "C_sur_date = C_sur_date.dropna(subset=['Cienega date'])\n",
    "C_im_date = C_im_date.dropna(subset=['date'])\n",
    "\n",
    "C_surveyData = pd.read_csv('../data/Cienega/Cienega_surveyData.csv')\n",
    "C_surveyData['Year'] = pd.to_datetime(C_surveyData['Year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e40101-6840-4b66-9463-fe3836524a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding closest matching dates between survey and imagery\n",
    "matching_dates = []\n",
    "tolerance = timedelta(days = 5)\n",
    "\n",
    "\n",
    "for date1 in C_sur_date['Cienega date']:\n",
    "    exact_date = False\n",
    "    tol = False \n",
    "    for date2 in C_im_date['date']:\n",
    "        if date1 == date2:\n",
    "            matching_dates.append({'Survey': date1, 'Imagery': date2})\n",
    "            exact_date = True\n",
    "    if not exact_date:\n",
    "        for date2 in C_im_date['date']:\n",
    "            if abs(date1 - date2) <= tolerance:\n",
    "                matching_dates.append({'Survey': date1, 'Imagery': date2})\n",
    "                tol = True\n",
    "        if not tol:\n",
    "            for date2 in C_im_date['date']:\n",
    "                if abs(date1-date2) < timedelta(days = 10): \n",
    "                    matching_dates.append({'Survey': date1, 'Imagery': date2})\n",
    "\n",
    "\n",
    "matching_dates_df = pd.DataFrame(matching_dates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59fcdb11-21ef-486c-9453-2c804317ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging dfs to use to determine imagery dates for survey dates\n",
    "C_datessurData = pd.merge(matching_dates_df, C_hyd, left_on = 'Survey', right_on = 'datetime', how = 'left')\n",
    "C_datesimData = pd.merge(matching_dates_df, C_hyd, left_on = 'Imagery', right_on = 'datetime')\n",
    "C_datessurData = C_datessurData.drop(columns = ['Imagery','datetime'])\n",
    "C_datesimData = C_datesimData.drop(columns = ['Survey','datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b120b39f-b3a4-496f-a222-d238759841c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum precipitation for dates in between survey and imagery\n",
    "def sum_pdatesbetween(d1, d2):\n",
    "    r = pd.date_range(start=min(d1,d2), end=max(d1,d2))\n",
    "    return C_hyd[C_hyd['datetime'].isin(r)]['P [mm]'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "877e5aee-1bfa-41a2-a45d-7a31efc27e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey</th>\n",
       "      <th>Imagery</th>\n",
       "      <th>sum_P</th>\n",
       "      <th>Q_diff [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-23</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>2017-03-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-06-09</td>\n",
       "      <td>2017-06-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-19</td>\n",
       "      <td>2017-09-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.587156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-12-08</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.803738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-06-05</td>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-09-08</td>\n",
       "      <td>2018-09-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-06-12</td>\n",
       "      <td>2020-06-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-09-17</td>\n",
       "      <td>2020-09-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>2020-12-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2021-12-13</td>\n",
       "      <td>2021-12-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2022-03-18</td>\n",
       "      <td>2022-03-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2022-06-03</td>\n",
       "      <td>2022-06-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>2022-12-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2023-06-08</td>\n",
       "      <td>2023-06-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Survey    Imagery  sum_P  Q_diff [%]\n",
       "0  2016-09-23 2016-09-22    0.0    0.000000\n",
       "1  2017-03-16 2017-03-13    0.0    0.000000\n",
       "2  2017-06-09 2017-06-09    0.0    0.000000\n",
       "3  2017-09-19 2017-09-21    0.0    4.587156\n",
       "6  2017-12-08 2017-12-07    0.0   -2.803738\n",
       "11 2018-06-05 2018-06-04    0.0    7.142857\n",
       "15 2018-09-08 2018-09-07    0.0    1.785714\n",
       "20 2018-12-17 2018-12-17    0.0    0.000000\n",
       "21 2019-03-26 2019-03-26    0.0    0.000000\n",
       "22 2019-06-07 2019-06-07    0.0    0.000000\n",
       "24 2019-12-13 2019-12-13    0.0    0.000000\n",
       "25 2020-03-24 2020-03-24    0.0    0.000000\n",
       "26 2020-06-12 2020-06-12    0.0    0.000000\n",
       "27 2020-09-17 2020-09-17    0.0    0.000000\n",
       "32 2020-12-18 2020-12-19    0.0   -5.263158\n",
       "34 2021-03-19 2021-03-19    0.0    0.000000\n",
       "35 2021-06-09 2021-06-09    0.0    0.000000\n",
       "36 2021-09-10 2021-09-10    0.0    0.000000\n",
       "37 2021-12-13 2021-12-13    0.0    0.000000\n",
       "38 2022-03-18 2022-03-18    0.0    0.000000\n",
       "43 2022-06-03 2022-06-02    0.0    1.136364\n",
       "49 2022-09-08 2022-09-07    0.0    2.400000\n",
       "53 2022-12-15 2022-12-17    0.0    0.000000\n",
       "55 2023-03-10 2023-03-10    0.0    0.000000\n",
       "56 2023-06-08 2023-06-08    0.0    0.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a dataframe to determine which imagery dates to use\n",
    "Ch = pd.DataFrame([])\n",
    "\n",
    "Ch['Survey'] = matching_dates_df['Survey']\n",
    "Ch['Imagery'] = matching_dates_df['Imagery']\n",
    "Ch['sum_P'] = [sum_pdatesbetween(C_datessurData.loc[i, 'Survey'], C_datesimData.loc[i, 'Imagery']) for i in range(len(Ch))]\n",
    "Ch['Q_diff [%]'] = (C_datessurData['Q [mm/d]'] - C_datesimData['Q [mm/d]']) / C_datessurData['Q [mm/d]'] * 100\n",
    "Ch['Use/not'] = ['use', 'use', 'use', 'use', 'not', 'not', 'use?',\n",
    "                 'not', 'only option', 'not', 'not', 'use', 'not',\n",
    "                 'not', 'not', 'use', 'not', 'not', 'not', 'not',\n",
    "                 'use', 'use', 'use', 'only option','use', 'use', \n",
    "                 'use','use', 'not', 'not', 'not', 'not', 'use', \n",
    "                 'not', 'use', 'use', 'use', 'use', 'use', 'not', \n",
    "                 'not', 'not', 'not', 'use', 'not', 'not', 'not', \n",
    "                 'not', 'not', 'use', 'not', 'not', 'not', 'use', \n",
    "                 'not', 'use', 'use']\n",
    "\n",
    "\n",
    "conditions = (Ch['sum_P'] > 3) | (Ch['Q_diff [%]'] > 8) | (Ch['Use/not'] == 'not')\n",
    "\n",
    "Ch = Ch[~conditions]\n",
    "\n",
    "Ch = Ch.drop(columns=['Use/not'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1d3a2e6-c9cf-4106-b335-dbf5ad595f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ch.to_csv('../data/Cienega/Cienega_survey_imagery_HydroData.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "880e49da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>Year</th>\n",
       "      <th>wetdry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (533719.252 3542427.373)</td>\n",
       "      <td>533719.252411</td>\n",
       "      <td>3.542427e+06</td>\n",
       "      <td>2004-06-25</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (533719.787 3542422.402)</td>\n",
       "      <td>533719.786671</td>\n",
       "      <td>3.542422e+06</td>\n",
       "      <td>2004-06-25</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (533720.321 3542417.431)</td>\n",
       "      <td>533720.320931</td>\n",
       "      <td>3.542417e+06</td>\n",
       "      <td>2004-06-25</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (533720.855 3542412.459)</td>\n",
       "      <td>533720.855191</td>\n",
       "      <td>3.542412e+06</td>\n",
       "      <td>2004-06-25</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (533721.389 3542407.488)</td>\n",
       "      <td>533721.389451</td>\n",
       "      <td>3.542407e+06</td>\n",
       "      <td>2004-06-25</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237685</th>\n",
       "      <td>POINT (533717.227 3542446.217)</td>\n",
       "      <td>533717.227336</td>\n",
       "      <td>3.542446e+06</td>\n",
       "      <td>2013-09-05</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237686</th>\n",
       "      <td>POINT (533717.762 3542441.246)</td>\n",
       "      <td>533717.761591</td>\n",
       "      <td>3.542441e+06</td>\n",
       "      <td>2013-09-05</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237687</th>\n",
       "      <td>POINT (533718.296 3542436.274)</td>\n",
       "      <td>533718.295846</td>\n",
       "      <td>3.542436e+06</td>\n",
       "      <td>2013-09-05</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237688</th>\n",
       "      <td>POINT (533718.830 3542431.303)</td>\n",
       "      <td>533718.830102</td>\n",
       "      <td>3.542431e+06</td>\n",
       "      <td>2013-09-05</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237689</th>\n",
       "      <td>POINT (539670.938 3540292.749)</td>\n",
       "      <td>539670.938285</td>\n",
       "      <td>3.540293e+06</td>\n",
       "      <td>2013-09-05</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237690 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              geometry              x             y  \\\n",
       "0       POINT (533719.252 3542427.373)  533719.252411  3.542427e+06   \n",
       "1       POINT (533719.787 3542422.402)  533719.786671  3.542422e+06   \n",
       "2       POINT (533720.321 3542417.431)  533720.320931  3.542417e+06   \n",
       "3       POINT (533720.855 3542412.459)  533720.855191  3.542412e+06   \n",
       "4       POINT (533721.389 3542407.488)  533721.389451  3.542407e+06   \n",
       "...                                ...            ...           ...   \n",
       "237685  POINT (533717.227 3542446.217)  533717.227336  3.542446e+06   \n",
       "237686  POINT (533717.762 3542441.246)  533717.761591  3.542441e+06   \n",
       "237687  POINT (533718.296 3542436.274)  533718.295846  3.542436e+06   \n",
       "237688  POINT (533718.830 3542431.303)  533718.830102  3.542431e+06   \n",
       "237689  POINT (539670.938 3540292.749)  539670.938285  3.540293e+06   \n",
       "\n",
       "             Year wetdry  \n",
       "0      2004-06-25    dry  \n",
       "1      2004-06-25    dry  \n",
       "2      2004-06-25    dry  \n",
       "3      2004-06-25    dry  \n",
       "4      2004-06-25    dry  \n",
       "...           ...    ...  \n",
       "237685 2013-09-05    dry  \n",
       "237686 2013-09-05    dry  \n",
       "237687 2013-09-05    dry  \n",
       "237688 2013-09-05    dry  \n",
       "237689 2013-09-05    dry  \n",
       "\n",
       "[237690 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading surveydata, making it into a geodataframe and adding x and y from the geometry to facilitate merge later \n",
    "#C_surveyData['geometry'] = C_surveyData['geometry'].apply(wkt.loads)\n",
    "C_surveyData = C_surveyData.set_geometry('geometry')\n",
    "gdf = gpd.GeoDataFrame(C_surveyData, geometry = 'geometry')#, crs='EPSG:26912')\n",
    "gdf['x'] = gdf.geometry.x\n",
    "gdf['y'] = gdf.geometry.y\n",
    "gdf = gdf[['geometry', 'x', 'y', 'wetdry', 'Year']]\n",
    "gdf['Year'] = pd.to_datetime(gdf['Year'])\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb368f91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m C_mergedata \u001b[38;5;241m=\u001b[39m Ch\u001b[38;5;241m.\u001b[39mmerge(gdf, left_on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvey\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m C_mergedata \u001b[38;5;241m=\u001b[39m C_mergedata\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvey\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum_P\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ_diff [\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Ch' is not defined"
     ]
    }
   ],
   "source": [
    "# using new data for precipitation \n",
    "C_new_hyd = C_hyd.merge(C_precipitation, left_on = 'datetime', right_on = 'day')\n",
    "C_new_hyd = C_new_hyd.drop(columns = ['day', 'P [mm]'])\n",
    "C_new_hyd.rename( columns={'P':'P [mm]'}, inplace=True )\n",
    "C_new_hyd.set_index(['datetime'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4057a74-ca6f-4dcc-936f-e46986f528f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to define assumptions around dates to choose, based on streamflow and precipitation\n",
    "# Q_condition could be completely removed\n",
    "def tolerance(Q_P_data, date, start, adjust, tolerance_p, P_condition = -999, Q_condition = -999):\n",
    "    \n",
    "    sub_grupp = Q_P_data.copy()\n",
    "    \n",
    "    if adjust == 'start':      \n",
    "        sub_grupp = Q_P_data.loc[start:].copy()       \n",
    "        \n",
    "    elif adjust == 'end': #reverse index to loop backwards\n",
    "        sub_grupp = sub_grupp.loc[:start].copy().iloc[::-1]        \n",
    "    \n",
    "    else:\n",
    "        print('Invalid adjust parameter. Please use \"start\" or \"end\"')\n",
    "        return\n",
    "\n",
    "    \n",
    "    # Reset index if reversed\n",
    "    sub_grupp.reset_index(inplace=True)\n",
    "\n",
    "    #creating a column for difference in streamflow\n",
    "    sub_grupp['Q_diff'] = sub_grupp['Q [mm/d]'].diff().fillna(0)\n",
    "\n",
    "    #checking to see if streamflow is overall decreasing, but a tolerance of x for any daily increase\n",
    "    if adjust == 'start':\n",
    "        sub_grupp['tolerance_condition'] = (sub_grupp.Q_diff < tolerance_p * sub_grupp['Q [mm/d]'])\n",
    "\n",
    "    if adjust == 'end':\n",
    "        sub_grupp['tolerance_condition'] = (sub_grupp.Q_diff > -tolerance_p * sub_grupp['Q [mm/d]'])\n",
    "\n",
    "    \n",
    "    if P_condition == -999 == Q_condition:\n",
    "        print('not a valid condition')\n",
    "        return \n",
    "        \n",
    "    elif P_condition == -999:\n",
    "        if Q_condition > 0:\n",
    "            sub_grupp['condition'] = sub_grupp['Q [mm/d]'] > Q_condition\n",
    "        else:\n",
    "            sub_grupp['condition'] = sub_grupp['Q [mm/d]'] < -Q_condition\n",
    "            \n",
    "    elif Q_condition == -999:\n",
    "        if P_condition > 0:\n",
    "            sub_grupp['condition'] = sub_grupp['P [mm]'] > P_condition\n",
    "        else:\n",
    "            sub_grupp['condition'] = sub_grupp['P [mm]'] < -P_condition\n",
    "            \n",
    "    else:\n",
    "        if (Q_condition > 0) & (P_condition > 0):\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] > Q_condition) & (sub_grupp['P [mm]'] > P_condition)\n",
    "        elif (Q_condition < 0) & (P_condition > 0):\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] < -Q_condition) & (sub_grupp['P [mm]'] > P_condition)           \n",
    "        elif (Q_condition > 0) & (P_condition < 0):\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] > Q_condition) & (sub_grupp['P [mm]'] < -P_condition)            \n",
    "        else:\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] < -Q_condition) & (sub_grupp['P [mm]'] < -P_condition)\n",
    "\n",
    "    # where both conditions are true\n",
    "    yesgroup = sub_grupp[(sub_grupp['condition'] == True) & (sub_grupp['tolerance_condition'] == True)] \n",
    "       \n",
    "    \n",
    "    if len(yesgroup) == 0:\n",
    "        print('No data where conditions are met')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    #the first instance where conditions are false after conditions hev been met \n",
    "    nogroup = sub_grupp[(sub_grupp['condition'] == False) | (sub_grupp['tolerance_condition'] == False)]  \n",
    "    \n",
    "    if len(nogroup) == 0:\n",
    "        print('nogroup = 0')\n",
    "        return sub_grupp.loc[yesgroup.index[0]:]\n",
    "\n",
    "    if yesgroup.index[0] < nogroup.index[0]:\n",
    "        print('everything is fine')\n",
    "        return sub_grupp.loc[:nogroup.index[0]]\n",
    "    \n",
    "    else:\n",
    "        print('No valid range found between yesgroup and nogroup indices')\n",
    "        return pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04c2d444-ae00-4668-a2ea-b77826c40347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Q [mm/d]</th>\n",
       "      <th>P [mm]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7702</th>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7703</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7704</th>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7705</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7706</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7707</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7708</th>\n",
       "      <td>2020-02-08</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7709</th>\n",
       "      <td>2020-02-09</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7710</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>10.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7711</th>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>1.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7712</th>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7753</th>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7754</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755</th>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7756</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7757</th>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7758</th>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7759</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7761</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime  Q [mm/d]  P [mm]\n",
       "7702 2020-02-02  0.001424   0.000\n",
       "7703 2020-02-03  0.001444   0.000\n",
       "7704 2020-02-04  0.001424   0.000\n",
       "7705 2020-02-05  0.001424   0.000\n",
       "7706 2020-02-06  0.001444   0.000\n",
       "7707 2020-02-07  0.001484   0.000\n",
       "7708 2020-02-08  0.001484   0.000\n",
       "7709 2020-02-09  0.001424   0.000\n",
       "7710 2020-02-10  0.001444  10.922\n",
       "7711 2020-02-11  0.001464   1.016\n",
       "7712 2020-02-12  0.001444   0.000\n",
       "7753 2020-03-24  0.001424   0.000\n",
       "7754 2020-03-25  0.001424   0.000\n",
       "7755 2020-03-26  0.001384   0.000\n",
       "7756 2020-03-27  0.001303   0.000\n",
       "7757 2020-03-28  0.001303   0.000\n",
       "7758 2020-03-29  0.001303   0.000\n",
       "7759 2020-03-30  0.001223   0.000\n",
       "7760 2020-03-31  0.001183   0.000\n",
       "7761 2020-04-01  0.001303   0.000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gdf['geometry_wkt'] = gdf['geometry'].apply(lambda geom: geom.wkt)\n",
    "# assuming perennial reaches\n",
    "perennial = pd.DataFrame(gdf.groupby('geometry')['wetdry'].apply(lambda x: sum(x == 'wet'))).reset_index(drop=False)\n",
    "perennialcount = pd.DataFrame(gdf.groupby('geometry')['wetdry'].count()).reset_index(drop=False)\n",
    "\n",
    "# whichever number is reasonable based on data?\n",
    "perennial = perennial[(perennial['wetdry'] >= (perennialcount['wetdry']))]\n",
    "\n",
    "#assume always wet\n",
    "perennial = perennial.assign(wetdry = 'wet')\n",
    "#perennial['geometry'] = perennial['geometry_wkt'].apply(wkt.loads)\n",
    "#perennial = perennial.drop(columns=['geometry_wkt'])\n",
    "\n",
    "#perennial['geometry'] = perennial['geometry'].apply(wkt.loads)\n",
    "gdf_perennial = gpd.GeoDataFrame(perennial, geometry = 'geometry')#, crs='EPSG:26912')\n",
    "gdf_perennial['x'] = gdf_perennial.geometry.x\n",
    "gdf_perennial['y'] = gdf_perennial.geometry.y\n",
    "\n",
    "#making the gdf matching the perennial reaches to all the imagery dates available \n",
    "imagery_perennial = pd.concat([gdf_perennial.assign(imagery = date) for date in C_im_date['date']], ignore_index=True)\n",
    "imagery_perennial = imagery_perennial[~imagery_perennial['imagery'].isin(Ch['Imagery'])]\n",
    "imagery_perennial['assumption'] = len(imagery_perennial)*['assumed perennial']\n",
    "imagery_perennial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4872e688-f795-4a79-b427-cd8b2a6a2d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assuming wet stretches for the dates before\n",
    "#assumption is made with 5 % difference in streamflow and for dates before survey when in a recession \n",
    "\n",
    "wet_list = []\n",
    "\n",
    "for date in C_surveyData['Year'].unique():\n",
    "            \n",
    "    wet1 = tolerance(C_new_hyd, 'datetime', date, 'end', 0.05, Q_condition = -999, P_condition = -1)\n",
    "    if len(wet1) == 0:\n",
    "        print('wet1 is empty')\n",
    "        continue\n",
    "    wet1 = wet1[~wet1['datetime'].isin(Ch['Imagery'])]\n",
    "    wet_imagery = pd.merge(wet1, C_im_date, left_on = ['datetime'], right_on = ['date'], how = 'inner')\n",
    "    #print(len(wet_imagery))\n",
    "    wet_points = pd.DataFrame(gdf[gdf['Year']== (date)].groupby('geometry')['wetdry'].apply(lambda x: sum(x == 'wet'))).reset_index(drop = False)\n",
    "    wet_points = wet_points[(wet_points['wetdry'] == 1)]\n",
    "    wet_points = wet_points.assign(wetdry = 'wet')\n",
    "    wet_im_points = [wet_points.assign(imagery = date) for date in wet_imagery['date']]\n",
    "        \n",
    "    try:\n",
    "        wet = pd.concat(wet_im_points).drop(columns = ['level_1'])\n",
    "        wet_list.append(wet)\n",
    "    except:\n",
    "        if len(wet_im_points)==0:\n",
    "            print('No data for date '+ date.strftime('%Y-%m-%d'))\n",
    "        else:\n",
    "            wet = wet_im_points[0]\n",
    "            wet_list.append(wet)\n",
    "        \n",
    "\n",
    "wet_df = pd.concat(wet_list)\n",
    "\n",
    "\n",
    "wet_df['assumption'] = len(wet_df)*['assumed wet']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e5c33-8b17-4ce7-ba72-25c2674500fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assuming dry stretches for the dates after\n",
    "#assumption is made with 5 % difference in streamflow and for dates after survey when in a recession \n",
    "\n",
    "dry_list = []\n",
    "\n",
    "\n",
    "for date in C_surveyData['Year'].unique():\n",
    "            \n",
    "    dry1 = tolerance(C_new_hyd, 'datetime', date, 'start', 0.05, Q_condition = -999, P_condition = -1)\n",
    "    if len(dry1) == 0:\n",
    "        print('wet1 is empty')\n",
    "        continue\n",
    "    dry1 = dry1[~dry1['datetime'].isin(Ch['Imagery'])]\n",
    "    dry_imagery = pd.merge(dry1, C_im_date, left_on = ['datetime'], right_on = ['date'], how = 'inner')\n",
    "        #print(len(wet_imagery))\n",
    "    dry_points = pd.DataFrame(gdf[gdf['Year']== (date)].groupby('geometry')['wetdry'].apply(lambda x: sum(x == 'dry'))).reset_index(drop = False)\n",
    "    dry_points = dry_points[(dry_points['wetdry'] == 1)].assign(wetdry = 'dry')\n",
    "    dry_im_points = [dry_points.assign(imagery = date) for date in dry_imagery['date']]\n",
    "        \n",
    "    try:\n",
    "        dry = pd.concat(dry_im_points).drop(columns = ['level_1'])\n",
    "        dry_list.append(dry)\n",
    "        \n",
    "    except:\n",
    "        if len(dry_im_points)==0:\n",
    "            print('No data for date '+ date.strftime('%Y-%m-%d'))\n",
    "        else:\n",
    "            dry = dry_im_points[0]\n",
    "            dry_list.append(dry)\n",
    "        #print(len(dry))\n",
    "        \n",
    "\n",
    "dry_df = pd.concat(dry_list)\n",
    "\n",
    "dry_df['assumption'] = len(dry_df)*['assumed dry']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74226f7-cd05-4586-ae77-c66bd71a61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all dfs with assumptions and survey matched to imagery dates and turn to gdf\n",
    "gdf['assumption'] = len(gdf)*['survey/imagery match']\n",
    "gdf_imagery = pd.merge(gdf, Ch, left_on = 'Year', right_on = 'Survey', how = 'left')\n",
    "gdf_imagery = gdf_imagery.drop(columns=['Survey', 'sum_P', 'Q_diff [%]', 'Year'])\n",
    "all_expanded = pd.concat([gdf_imagery, imagery_perennial, wet_df, dry_df])\n",
    "all_expanded = gpd.GeoDataFrame(all_expanded, geometry = 'geometry', crs='EPSG:26912')\n",
    "all_expanded['x'] = all_expanded.geometry.x\n",
    "all_expanded['y'] = all_expanded.geometry.y\n",
    "all_expanded = all_expanded.rename(columns = {'imagery':'date_first'})\n",
    "all_expanded['date'] = all_expanded['Imagery'].combine_first(all_expanded['date_first'])\n",
    "all_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8449ef5-28ea-4775-89aa-fa061a7c64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading and concatenating the processed imagery \n",
    "path = '../data/Cienega/processed_imagery'\n",
    "\n",
    "processed_imagery = glob.glob(path + '/*.csv')\n",
    "processed_imagery.sort(key = lambda x: int(x.split('_buffer_')[1].split('.')[0]))\n",
    "con_ready_imagery = []\n",
    "for processed in processed_imagery:\n",
    "    df= pd.read_csv(processed)\n",
    "    con_ready_imagery.append(df)\n",
    "\n",
    "concatenated = pd.concat(con_ready_imagery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8e02208-2077-4fef-a1e0-6bd15b6c1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated['geometry'] = concatenated['geometry'].apply(wkt.loads)\n",
    "gdf_processed = gpd.GeoDataFrame(concatenated, geometry = 'geometry', crs='EPSG:26912')\n",
    "gdf_processed['date'] = pd.to_datetime(gdf_processed['date'], format='%Y%m%d')\n",
    "gdf_processed['x'] = gdf_processed.geometry.x\n",
    "gdf_processed['y'] = gdf_processed.geometry.y\n",
    "gdf_processed = gdf_processed.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4264da09-bd77-43ca-bb2d-745ea3af7290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "      <th>NIR</th>\n",
       "      <th>missing</th>\n",
       "      <th>NDWI</th>\n",
       "      <th>p</th>\n",
       "      <th>date</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>866.78</td>\n",
       "      <td>1160.78</td>\n",
       "      <td>1527.67</td>\n",
       "      <td>2449.56</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0</td>\n",
       "      <td>20181121</td>\n",
       "      <td>POINT (533719.252 3542427.373)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>869.89</td>\n",
       "      <td>1168.11</td>\n",
       "      <td>1497.22</td>\n",
       "      <td>2404.89</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0</td>\n",
       "      <td>20181121</td>\n",
       "      <td>POINT (533719.787 3542422.402)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>893.56</td>\n",
       "      <td>1189.44</td>\n",
       "      <td>1491.22</td>\n",
       "      <td>2383.44</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>20181121</td>\n",
       "      <td>POINT (533720.321 3542417.431)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>939.78</td>\n",
       "      <td>1227.22</td>\n",
       "      <td>1530.89</td>\n",
       "      <td>2385.56</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>20181121</td>\n",
       "      <td>POINT (533720.855 3542412.459)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1072.67</td>\n",
       "      <td>1341.00</td>\n",
       "      <td>1730.22</td>\n",
       "      <td>2272.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>20181121</td>\n",
       "      <td>POINT (533721.389 3542407.488)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232300</th>\n",
       "      <td>634.67</td>\n",
       "      <td>998.44</td>\n",
       "      <td>1149.78</td>\n",
       "      <td>3126.22</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0</td>\n",
       "      <td>20230701</td>\n",
       "      <td>POINT (533717.227 3542446.217)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232301</th>\n",
       "      <td>666.89</td>\n",
       "      <td>1041.00</td>\n",
       "      <td>1218.00</td>\n",
       "      <td>3116.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>20230701</td>\n",
       "      <td>POINT (533717.762 3542441.246)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232302</th>\n",
       "      <td>806.11</td>\n",
       "      <td>1202.67</td>\n",
       "      <td>1484.00</td>\n",
       "      <td>3275.33</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>20230701</td>\n",
       "      <td>POINT (533718.296 3542436.274)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232303</th>\n",
       "      <td>871.67</td>\n",
       "      <td>1294.00</td>\n",
       "      <td>1620.00</td>\n",
       "      <td>3227.22</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>20230701</td>\n",
       "      <td>POINT (533718.830 3542431.303)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232304</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>20230701</td>\n",
       "      <td>POINT (539670.938 3540292.749)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9292194 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           blue    green      red      NIR  missing  NDWI  p      date  \\\n",
       "0        866.78  1160.78  1527.67  2449.56        0 -0.36  0  20181121   \n",
       "1        869.89  1168.11  1497.22  2404.89        0 -0.35  0  20181121   \n",
       "2        893.56  1189.44  1491.22  2383.44        0 -0.33  0  20181121   \n",
       "3        939.78  1227.22  1530.89  2385.56        0 -0.32  0  20181121   \n",
       "4       1072.67  1341.00  1730.22  2272.00        0 -0.26  0  20181121   \n",
       "...         ...      ...      ...      ...      ...   ... ..       ...   \n",
       "232300   634.67   998.44  1149.78  3126.22        0 -0.52  0  20230701   \n",
       "232301   666.89  1041.00  1218.00  3116.00        0 -0.50  0  20230701   \n",
       "232302   806.11  1202.67  1484.00  3275.33        0 -0.46  0  20230701   \n",
       "232303   871.67  1294.00  1620.00  3227.22        0 -0.43  0  20230701   \n",
       "232304     0.00     0.00     0.00     0.00        0   NaN  0  20230701   \n",
       "\n",
       "                              geometry  \n",
       "0       POINT (533719.252 3542427.373)  \n",
       "1       POINT (533719.787 3542422.402)  \n",
       "2       POINT (533720.321 3542417.431)  \n",
       "3       POINT (533720.855 3542412.459)  \n",
       "4       POINT (533721.389 3542407.488)  \n",
       "...                                ...  \n",
       "232300  POINT (533717.227 3542446.217)  \n",
       "232301  POINT (533717.762 3542441.246)  \n",
       "232302  POINT (533718.296 3542436.274)  \n",
       "232303  POINT (533718.830 3542431.303)  \n",
       "232304  POINT (539670.938 3540292.749)  \n",
       "\n",
       "[9292194 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = 6\n",
    "all_expanded['x'] = all_expanded['x'].round(precision)\n",
    "all_expanded['y'] = all_expanded['y'].round(precision)\n",
    "gdf_processed['x'] = gdf_processed['x'].round(precision)\n",
    "gdf_processed['y'] = gdf_processed['y'].round(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609f457-9b11-4a8b-aa11-2c9177bd3578",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = all_expanded.merge(gdf_processed, on=['date', 'x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f9ab5-691c-4e20-8ce2-80d629ba6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.drop(columns = ['geometry_x', 'geometry_y', 'Imagery', 'date_first']) \n",
    "merged_sorted = merged.sort_values(by='date')\n",
    "merged_sorted = merged_sorted.drop_duplicates()\n",
    "merged_sorted.dropna(inplace= True)\n",
    "merged_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482dd362-9c0c-4157-a19c-79cccbaee270",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "splitnum = 10\n",
    "for i in range(1,splitnum+1):\n",
    "    newstart = int(len(merged_sorted)/splitnum*i)\n",
    "    merged_sorted.iloc[start:newstart].to_csv('../data/Cienega/processed_assumptions/processed_with_dates_and_assumptions'+str(i)+'.csv',index=False,\n",
    "                      float_format='%.2f')\n",
    "    start = newstart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000cf055-8029-4d76-a6d5-65a3d1b956c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452e608-c3ce-4b94-a3f8-a24e228ff95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6bf3f9-ba52-45bc-be7c-6f9368ec2451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
