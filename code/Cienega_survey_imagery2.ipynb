{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0714e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/geohelp/lib/python3.12/site-packages/pyproj/__init__.py:89: UserWarning: pyproj unable to set database path.\n",
      "  _pyproj_global_context_initialize()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv \n",
    "import geopandas as gpd\n",
    "from datetime import timedelta\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed5fa590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv files and adjust to datetime\n",
    "C_im_date = pd.read_csv('../data/Cienega/CienegaImageryDates.csv', parse_dates=['date'])\n",
    "C_sur_date = pd.read_csv('../data/Cienega/Cienega_survey_dates.csv', parse_dates=['Cienega date'])\n",
    "C_sur_date['Cienega date'] = pd.to_datetime(C_sur_date['Cienega date'])\n",
    "C_im_date['date'] = pd.to_datetime(C_im_date['date'])\n",
    "\n",
    "C_hyd = pd.read_csv('../data/Cienega/CienegaHydroData.csv')\n",
    "C_hyd['datetime'] = pd.to_datetime(C_hyd['datetime'])\n",
    "\n",
    "C_precipitation = pd.read_csv('../data/Cienega/daymet_precip.csv')\n",
    "C_precipitation['system:time_start'] = pd.to_datetime(C_precipitation['system:time_start'])\n",
    "C_precipitation.rename( columns={'00000000000000000000':'P','system:time_start':'day'}, inplace=True )\n",
    "\n",
    "C_sur_date = C_sur_date.dropna(subset=['Cienega date'])\n",
    "C_im_date = C_im_date.dropna(subset=['date'])\n",
    "\n",
    "C_surveyData = pd.read_csv('../data/Cienega/Cienega_surveyData.csv')\n",
    "C_surveyData['Year'] = pd.to_datetime(C_surveyData['Year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e40101-6840-4b66-9463-fe3836524a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding closest matching dates between survey and imagery\n",
    "matching_dates = []\n",
    "tolerance = timedelta(days = 5)\n",
    "\n",
    "\n",
    "for date1 in C_sur_date['Cienega date']:\n",
    "    exact_date = False\n",
    "    tol = False \n",
    "    for date2 in C_im_date['date']:\n",
    "        if date1 == date2:\n",
    "            matching_dates.append({'Survey': date1, 'Imagery': date2})\n",
    "            exact_date = True\n",
    "    if not exact_date:\n",
    "        for date2 in C_im_date['date']:\n",
    "            if abs(date1 - date2) <= tolerance:\n",
    "                matching_dates.append({'Survey': date1, 'Imagery': date2})\n",
    "                tol = True\n",
    "        if not tol:\n",
    "            for date2 in C_im_date['date']:\n",
    "                if abs(date1-date2) < timedelta(days = 10): \n",
    "                    matching_dates.append({'Survey': date1, 'Imagery': date2})\n",
    "\n",
    "\n",
    "matching_dates_df = pd.DataFrame(matching_dates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59fcdb11-21ef-486c-9453-2c804317ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging dfs to use to determine imagery dates for survey dates\n",
    "C_datessurData = pd.merge(matching_dates_df, C_hyd, left_on = 'Survey', right_on = 'datetime', how = 'left')\n",
    "C_datesimData = pd.merge(matching_dates_df, C_hyd, left_on = 'Imagery', right_on = 'datetime')\n",
    "C_datessurData = C_datessurData.drop(columns = ['Imagery','datetime'])\n",
    "C_datesimData = C_datesimData.drop(columns = ['Survey','datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b120b39f-b3a4-496f-a222-d238759841c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum precipitation for dates in between survey and imagery\n",
    "def sum_pdatesbetween(d1, d2):\n",
    "    r = pd.date_range(start=min(d1,d2), end=max(d1,d2))\n",
    "    return C_hyd[C_hyd['datetime'].isin(r)]['P [mm]'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "877e5aee-1bfa-41a2-a45d-7a31efc27e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe to determine which imagery dates to use\n",
    "Ch = pd.DataFrame([])\n",
    "\n",
    "Ch['Survey'] = matching_dates_df['Survey']\n",
    "Ch['Imagery'] = matching_dates_df['Imagery']\n",
    "Ch['sum_P'] = [sum_pdatesbetween(C_datessurData.loc[i, 'Survey'], C_datesimData.loc[i, 'Imagery']) for i in range(len(Ch))]\n",
    "Ch['Q_diff [%]'] = (C_datessurData['Q [mm/d]'] - C_datesimData['Q [mm/d]']) / C_datessurData['Q [mm/d]'] * 100\n",
    "Ch['Use/not'] = ['use', 'use', 'use', 'use', 'not', 'not', 'use?',\n",
    "                 'not', 'only option', 'not', 'not', 'use', 'not',\n",
    "                 'not', 'not', 'use', 'not', 'not', 'not', 'not',\n",
    "                 'use', 'use', 'use', 'only option','use', 'use', \n",
    "                 'use','use', 'not', 'not', 'not', 'not', 'use', \n",
    "                 'not', 'use', 'use', 'use', 'use', 'use', 'not', \n",
    "                 'not', 'not', 'not', 'use', 'not', 'not', 'not', \n",
    "                 'not', 'not', 'use', 'not', 'not', 'not', 'use', \n",
    "                 'not', 'use', 'use']\n",
    "\n",
    "\n",
    "conditions = (Ch['sum_P'] > 3) | (Ch['Q_diff [%]'] > 8) | (Ch['Use/not'] == 'not')\n",
    "\n",
    "Ch = Ch[~conditions]\n",
    "\n",
    "Ch = Ch.drop(columns=['Use/not'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d3a2e6-c9cf-4106-b335-dbf5ad595f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ch.to_csv('../data/Cienega/Cienega_survey_imagery_HydroData.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d98f91b4-fb7f-4269-bd9a-31619dc7f09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Year</th>\n",
       "      <th>wetdry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>POINT (533719.2524112025 3542427.373284319)</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>POINT (533719.7866711848 3542422.401909633)</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>POINT (533720.320931167 3542417.430534947)</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (533720.8551911493 3542412.45916026)</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>POINT (533721.3894511315 3542407.487785575)</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89789</th>\n",
       "      <td>2636</td>\n",
       "      <td>POINT (533717.2273356403 3542446.217103646)</td>\n",
       "      <td>2023-06-08</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89790</th>\n",
       "      <td>2637</td>\n",
       "      <td>POINT (533717.7615909434 3542441.245728457)</td>\n",
       "      <td>2023-06-08</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89791</th>\n",
       "      <td>2638</td>\n",
       "      <td>POINT (533718.2958462465 3542436.274353268)</td>\n",
       "      <td>2023-06-08</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89792</th>\n",
       "      <td>2639</td>\n",
       "      <td>POINT (533718.8301015496 3542431.302978079)</td>\n",
       "      <td>2023-06-08</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89793</th>\n",
       "      <td>2640</td>\n",
       "      <td>POINT (539670.9382846388 3540292.748781616)</td>\n",
       "      <td>2023-06-08</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89794 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                     geometry       Year  \\\n",
       "0               0  POINT (533719.2524112025 3542427.373284319) 2015-12-09   \n",
       "1               1  POINT (533719.7866711848 3542422.401909633) 2015-12-09   \n",
       "2               2   POINT (533720.320931167 3542417.430534947) 2015-12-09   \n",
       "3               3   POINT (533720.8551911493 3542412.45916026) 2015-12-09   \n",
       "4               4  POINT (533721.3894511315 3542407.487785575) 2015-12-09   \n",
       "...           ...                                          ...        ...   \n",
       "89789        2636  POINT (533717.2273356403 3542446.217103646) 2023-06-08   \n",
       "89790        2637  POINT (533717.7615909434 3542441.245728457) 2023-06-08   \n",
       "89791        2638  POINT (533718.2958462465 3542436.274353268) 2023-06-08   \n",
       "89792        2639  POINT (533718.8301015496 3542431.302978079) 2023-06-08   \n",
       "89793        2640  POINT (539670.9382846388 3540292.748781616) 2023-06-08   \n",
       "\n",
       "      wetdry  \n",
       "0        dry  \n",
       "1        dry  \n",
       "2        dry  \n",
       "3        dry  \n",
       "4        dry  \n",
       "...      ...  \n",
       "89789    dry  \n",
       "89790    dry  \n",
       "89791    dry  \n",
       "89792    dry  \n",
       "89793    dry  \n",
       "\n",
       "[89794 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_surveyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "880e49da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>wetdry</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (533719.252 3542427.373)</td>\n",
       "      <td>533719.252411</td>\n",
       "      <td>3.542427e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2015-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (533719.787 3542422.402)</td>\n",
       "      <td>533719.786671</td>\n",
       "      <td>3.542422e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2015-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (533720.321 3542417.431)</td>\n",
       "      <td>533720.320931</td>\n",
       "      <td>3.542417e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2015-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (533720.855 3542412.459)</td>\n",
       "      <td>533720.855191</td>\n",
       "      <td>3.542412e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2015-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (533721.389 3542407.488)</td>\n",
       "      <td>533721.389451</td>\n",
       "      <td>3.542407e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2015-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89789</th>\n",
       "      <td>POINT (533717.227 3542446.217)</td>\n",
       "      <td>533717.227336</td>\n",
       "      <td>3.542446e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2023-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89790</th>\n",
       "      <td>POINT (533717.762 3542441.246)</td>\n",
       "      <td>533717.761591</td>\n",
       "      <td>3.542441e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2023-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89791</th>\n",
       "      <td>POINT (533718.296 3542436.274)</td>\n",
       "      <td>533718.295846</td>\n",
       "      <td>3.542436e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2023-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89792</th>\n",
       "      <td>POINT (533718.830 3542431.303)</td>\n",
       "      <td>533718.830102</td>\n",
       "      <td>3.542431e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2023-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89793</th>\n",
       "      <td>POINT (539670.938 3540292.749)</td>\n",
       "      <td>539670.938285</td>\n",
       "      <td>3.540293e+06</td>\n",
       "      <td>dry</td>\n",
       "      <td>2023-06-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89794 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             geometry              x             y wetdry  \\\n",
       "0      POINT (533719.252 3542427.373)  533719.252411  3.542427e+06    dry   \n",
       "1      POINT (533719.787 3542422.402)  533719.786671  3.542422e+06    dry   \n",
       "2      POINT (533720.321 3542417.431)  533720.320931  3.542417e+06    dry   \n",
       "3      POINT (533720.855 3542412.459)  533720.855191  3.542412e+06    dry   \n",
       "4      POINT (533721.389 3542407.488)  533721.389451  3.542407e+06    dry   \n",
       "...                               ...            ...           ...    ...   \n",
       "89789  POINT (533717.227 3542446.217)  533717.227336  3.542446e+06    dry   \n",
       "89790  POINT (533717.762 3542441.246)  533717.761591  3.542441e+06    dry   \n",
       "89791  POINT (533718.296 3542436.274)  533718.295846  3.542436e+06    dry   \n",
       "89792  POINT (533718.830 3542431.303)  533718.830102  3.542431e+06    dry   \n",
       "89793  POINT (539670.938 3540292.749)  539670.938285  3.540293e+06    dry   \n",
       "\n",
       "            Year  \n",
       "0     2015-12-09  \n",
       "1     2015-12-09  \n",
       "2     2015-12-09  \n",
       "3     2015-12-09  \n",
       "4     2015-12-09  \n",
       "...          ...  \n",
       "89789 2023-06-08  \n",
       "89790 2023-06-08  \n",
       "89791 2023-06-08  \n",
       "89792 2023-06-08  \n",
       "89793 2023-06-08  \n",
       "\n",
       "[89794 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading surveydata, making it into a geodataframe and adding x and y from the geometry to facilitate merge later \n",
    "#C_surveyData['geometry'] = C_surveyData['geometry'].apply(wkt.loads)\n",
    "C_surveyData = C_surveyData.set_geometry('geometry')\n",
    "gdf = gpd.GeoDataFrame(C_surveyData, geometry = 'geometry')#, crs='EPSG:26912')\n",
    "gdf['x'] = gdf.geometry.x\n",
    "gdf['y'] = gdf.geometry.y\n",
    "gdf = gdf[['geometry', 'x', 'y', 'wetdry', 'Year']]\n",
    "gdf['Year'] = pd.to_datetime(gdf['Year'])\n",
    "\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb368f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using new data for precipitation \n",
    "C_new_hyd = C_hyd.merge(C_precipitation, left_on = 'datetime', right_on = 'day')\n",
    "C_new_hyd = C_new_hyd.drop(columns = ['day', 'P [mm]'])\n",
    "C_new_hyd.rename( columns={'P':'P [mm]'}, inplace=True )\n",
    "C_new_hyd.set_index(['datetime'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4057a74-ca6f-4dcc-936f-e46986f528f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to define assumptions around dates to choose, based on streamflow and precipitation\n",
    "# Q_condition could be completely removed\n",
    "def tolerance(Q_P_data, date, start, adjust, tolerance_p, P_condition = -999, Q_condition = -999):\n",
    "    \n",
    "    sub_grupp = Q_P_data.copy()\n",
    "    \n",
    "    if adjust == 'start':      \n",
    "        sub_grupp = Q_P_data.loc[start:].copy()       \n",
    "        \n",
    "    elif adjust == 'end': #reverse index to loop backwards\n",
    "        sub_grupp = sub_grupp.loc[:start].copy().iloc[::-1]        \n",
    "    \n",
    "    else:\n",
    "        print('Invalid adjust parameter. Please use \"start\" or \"end\"')\n",
    "        return\n",
    "\n",
    "    \n",
    "    # Reset index if reversed\n",
    "    sub_grupp.reset_index(inplace=True)\n",
    "\n",
    "    #creating a column for difference in streamflow\n",
    "    sub_grupp['Q_diff'] = sub_grupp['Q [mm/d]'].diff().fillna(0)\n",
    "\n",
    "    #checking to see if streamflow is overall decreasing, but a tolerance of x for any daily increase\n",
    "    if adjust == 'start':\n",
    "        sub_grupp['tolerance_condition'] = (sub_grupp.Q_diff < tolerance_p * sub_grupp['Q [mm/d]'])\n",
    "\n",
    "    if adjust == 'end':\n",
    "        sub_grupp['tolerance_condition'] = (sub_grupp.Q_diff > -tolerance_p * sub_grupp['Q [mm/d]'])\n",
    "\n",
    "    \n",
    "    if P_condition == -999 == Q_condition:\n",
    "        print('not a valid condition')\n",
    "        return \n",
    "        \n",
    "    elif P_condition == -999:\n",
    "        if Q_condition > 0:\n",
    "            sub_grupp['condition'] = sub_grupp['Q [mm/d]'] > Q_condition\n",
    "        else:\n",
    "            sub_grupp['condition'] = sub_grupp['Q [mm/d]'] < -Q_condition\n",
    "            \n",
    "    elif Q_condition == -999:\n",
    "        if P_condition > 0:\n",
    "            sub_grupp['condition'] = sub_grupp['P [mm]'] > P_condition\n",
    "        else:\n",
    "            sub_grupp['condition'] = sub_grupp['P [mm]'] < -P_condition\n",
    "            \n",
    "    else:\n",
    "        if (Q_condition > 0) & (P_condition > 0):\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] > Q_condition) & (sub_grupp['P [mm]'] > P_condition)\n",
    "        elif (Q_condition < 0) & (P_condition > 0):\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] < -Q_condition) & (sub_grupp['P [mm]'] > P_condition)           \n",
    "        elif (Q_condition > 0) & (P_condition < 0):\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] > Q_condition) & (sub_grupp['P [mm]'] < -P_condition)            \n",
    "        else:\n",
    "            sub_grupp['condition'] = (sub_grupp['Q [mm/d]'] < -Q_condition) & (sub_grupp['P [mm]'] < -P_condition)\n",
    "\n",
    "    # where both conditions are true\n",
    "    yesgroup = sub_grupp[(sub_grupp['condition'] == True) & (sub_grupp['tolerance_condition'] == True)] \n",
    "       \n",
    "    \n",
    "    if len(yesgroup) == 0:\n",
    "        print('No data where conditions are met')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    #the first instance where conditions are false after conditions hev been met \n",
    "    nogroup = sub_grupp[(sub_grupp['condition'] == False) | (sub_grupp['tolerance_condition'] == False)]  \n",
    "    \n",
    "    if len(nogroup) == 0:\n",
    "        print('nogroup = 0')\n",
    "        return sub_grupp.loc[yesgroup.index[0]:]\n",
    "\n",
    "    if yesgroup.index[0] < nogroup.index[0]:\n",
    "        print('everything is fine')\n",
    "        return sub_grupp.loc[:nogroup.index[0]]\n",
    "    \n",
    "    else:\n",
    "        print('No valid range found between yesgroup and nogroup indices')\n",
    "        return pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a62cc9b4-5bf8-4113-a61c-e595d7d220f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>wetdry</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>imagery</th>\n",
       "      <th>assumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [geometry, wetdry, x, y, imagery, assumption]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#formatting the geometry so it can be used in sum()\n",
    "\n",
    "#gdf['geometry_wkt'] = gdf['geometry'].apply(lambda geom: geom.wkt)\n",
    "# assuming perennial reaches\n",
    "perennial = pd.DataFrame(gdf.groupby('geometry')['wetdry'].apply(lambda x: sum(x == 'wet'))).reset_index(drop=False)\n",
    "perennialcount = pd.DataFrame(gdf.groupby('geometry')['wetdry'].count()).reset_index(drop=False)\n",
    "\n",
    "# whichever number is reasonable based on data?\n",
    "perennial = perennial[(perennial['wetdry'] >= (perennialcount['wetdry']))]\n",
    "\n",
    "#assume always wet\n",
    "perennial = perennial.assign(wetdry = 'wet')\n",
    "#perennial['geometry'] = perennial['geometry_wkt'].apply(wkt.loads)\n",
    "#perennial = perennial.drop(columns=['geometry_wkt'])\n",
    "\n",
    "#perennial['geometry'] = perennial['geometry'].apply(wkt.loads)\n",
    "gdf_perennial = gpd.GeoDataFrame(perennial, geometry = 'geometry')#, crs='EPSG:26912')\n",
    "gdf_perennial['x'] = gdf_perennial.geometry.x\n",
    "gdf_perennial['y'] = gdf_perennial.geometry.y\n",
    "\n",
    "#making the gdf matching the perennial reaches to all the imagery dates available \n",
    "imagery_perennial = pd.concat([gdf_perennial.assign(imagery = date) for date in C_im_date['date']], ignore_index=True)\n",
    "imagery_perennial = imagery_perennial[~imagery_perennial['imagery'].isin(Ch['Imagery'])]\n",
    "imagery_perennial['assumption'] = len(imagery_perennial)*['assumed perennial']\n",
    "imagery_perennial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c06907ea-5ba4-4986-a553-8242f0a2738b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>wetdry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (535086.573 3541970.310)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (535081.632 3541971.076)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (535076.691 3541971.843)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (535071.750 3541972.609)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (535066.809 3541973.376)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>POINT (539511.378 3540289.598)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>POINT (539516.317 3540290.375)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>POINT (539396.748 3540256.611)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>POINT (539392.098 3540254.772)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>POINT (539387.449 3540252.933)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2641 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            geometry  wetdry\n",
       "0     POINT (535086.573 3541970.310)      34\n",
       "1     POINT (535081.632 3541971.076)      34\n",
       "2     POINT (535076.691 3541971.843)      34\n",
       "3     POINT (535071.750 3541972.609)      34\n",
       "4     POINT (535066.809 3541973.376)      34\n",
       "...                              ...     ...\n",
       "2636  POINT (539511.378 3540289.598)      34\n",
       "2637  POINT (539516.317 3540290.375)      34\n",
       "2638  POINT (539396.748 3540256.611)      34\n",
       "2639  POINT (539392.098 3540254.772)      34\n",
       "2640  POINT (539387.449 3540252.933)      34\n",
       "\n",
       "[2641 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perennial = pd.DataFrame(gdf.groupby('geometry')['wetdry'].apply(lambda x: sum(x == 'wet'))).reset_index(drop=False)\n",
    "perennialcount = pd.DataFrame(gdf.groupby('geometry')['wetdry'].count()).reset_index(drop=False)\n",
    "\n",
    "perennialcount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04c2d444-ae00-4668-a2ea-b77826c40347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "No data where conditions are met\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2016-06-03\n",
      "everything is fine\n",
      "No data for date 2016-09-23\n",
      "No valid range found between yesgroup and nogroup indices\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2016-03-18\n",
      "everything is fine\n",
      "No data for date 2017-06-09\n",
      "everything is fine\n",
      "No data for date 2017-09-19\n",
      "everything is fine\n",
      "No data for date 2017-12-08\n",
      "everything is fine\n",
      "No data for date 2017-03-16\n",
      "everything is fine\n",
      "No data for date 2018-06-05\n",
      "everything is fine\n",
      "No valid range found between yesgroup and nogroup indices\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "No data for date 2018-03-23\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2019-09-13\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2020-09-17\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "No valid range found between yesgroup and nogroup indices\n",
      "wet1 is empty\n",
      "everything is fine\n",
      "everything is fine\n",
      "No data for date 2022-12-15\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n",
      "everything is fine\n"
     ]
    }
   ],
   "source": [
    "#assuming wet stretches for the dates before\n",
    "#assumption is made with 5 % difference in streamflow and for dates before survey when in a recession \n",
    "\n",
    "wet_list = []\n",
    "\n",
    "for date in C_surveyData['Year'].unique():\n",
    "            \n",
    "    wet1 = tolerance(C_new_hyd, 'datetime', date, 'end', 0.05, Q_condition = -999, P_condition = -1)\n",
    "    if len(wet1) == 0:\n",
    "        print('wet1 is empty')\n",
    "        continue\n",
    "    wet1 = wet1[~wet1['datetime'].isin(Ch['Imagery'])]\n",
    "    wet_imagery = pd.merge(wet1, C_im_date, left_on = ['datetime'], right_on = ['date'], how = 'inner')\n",
    "    #print(len(wet_imagery))\n",
    "    wet_points = pd.DataFrame(gdf[gdf['Year']== (date)].groupby('geometry')['wetdry'].apply(lambda x: sum(x == 'wet'))).reset_index(drop = False)\n",
    "    wet_points = wet_points[(wet_points['wetdry'] == 1)]\n",
    "    wet_points = wet_points.assign(wetdry = 'wet')\n",
    "    wet_im_points = [wet_points.assign(imagery = date) for date in wet_imagery['date']]\n",
    "        \n",
    "    try:\n",
    "        wet = pd.concat(wet_im_points).drop(columns = ['level_1'])\n",
    "        wet_list.append(wet)\n",
    "    except:\n",
    "        if len(wet_im_points)==0:\n",
    "            print('No data for date '+ date.strftime('%Y-%m-%d'))\n",
    "        else:\n",
    "            wet = wet_im_points[0]\n",
    "            wet_list.append(wet)\n",
    "        \n",
    "\n",
    "wet_df = pd.concat(wet_list)\n",
    "\n",
    "\n",
    "wet_df['assumption'] = len(wet_df)*['assumed wet']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4872e688-f795-4a79-b427-cd8b2a6a2d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assuming dry stretches for the dates after\n",
    "#assumption is made with 5 % difference in streamflow and for dates after survey when in a recession \n",
    "\n",
    "dry_list = []\n",
    "\n",
    "\n",
    "for date in C_surveyData['Year'].unique():\n",
    "            \n",
    "    dry1 = tolerance(C_new_hyd, 'datetime', date, 'start', 0.05, Q_condition = -999, P_condition = -1)\n",
    "    if len(dry1) == 0:\n",
    "        print('wet1 is empty')\n",
    "        continue\n",
    "    dry1 = dry1[~dry1['datetime'].isin(Ch['Imagery'])]\n",
    "    dry_imagery = pd.merge(dry1, C_im_date, left_on = ['datetime'], right_on = ['date'], how = 'inner')\n",
    "        #print(len(wet_imagery))\n",
    "    dry_points = pd.DataFrame(gdf[gdf['Year']== (date)].groupby('geometry')['wetdry'].apply(lambda x: sum(x == 'dry'))).reset_index(drop = False)\n",
    "    dry_points = dry_points[(dry_points['wetdry'] == 1)].assign(wetdry = 'dry')\n",
    "    dry_im_points = [dry_points.assign(imagery = date) for date in dry_imagery['date']]\n",
    "        \n",
    "    try:\n",
    "        dry = pd.concat(dry_im_points).drop(columns = ['level_1'])\n",
    "        dry_list.append(dry)\n",
    "        \n",
    "    except:\n",
    "        if len(dry_im_points)==0:\n",
    "            print('No data for date '+ date.strftime('%Y-%m-%d'))\n",
    "        else:\n",
    "            dry = dry_im_points[0]\n",
    "            dry_list.append(dry)\n",
    "        #print(len(dry))\n",
    "        \n",
    "\n",
    "dry_df = pd.concat(dry_list)\n",
    "\n",
    "dry_df['assumption'] = len(dry_df)*['assumed dry']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0d5c99-5dd0-48dd-b13a-00c4e5c0f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all dfs with assumptions and survey matched to imagery dates and turn to gdf\n",
    "gdf['assumption'] = len(gdf)*['survey/imagery match']\n",
    "gdf_imagery = pd.merge(gdf, Ch, left_on = 'Year', right_on = 'Survey', how = 'left')\n",
    "gdf_imagery = gdf_imagery.drop(columns=['Survey', 'sum_P', 'Q_diff [%]', 'Year'])\n",
    "all_expanded = pd.concat([gdf_imagery, imagery_perennial, wet_df, dry_df])\n",
    "all_expanded = gpd.GeoDataFrame(all_expanded, geometry = 'geometry', crs='EPSG:26912')\n",
    "all_expanded['x'] = all_expanded.geometry.x\n",
    "all_expanded['y'] = all_expanded.geometry.y\n",
    "all_expanded = all_expanded.rename(columns = {'imagery':'date_first'})\n",
    "all_expanded['date'] = all_expanded['Imagery'].combine_first(all_expanded['date_first'])\n",
    "all_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8449ef5-28ea-4775-89aa-fa061a7c64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading and concatenating the processed imagery \n",
    "path = '../data/Cienega/processed_imagery'\n",
    "\n",
    "processed_imagery = glob.glob(path + '/*.csv')\n",
    "processed_imagery.sort(key = lambda x: int(x.split('_buffer_')[1].split('.')[0]))\n",
    "con_ready_imagery = []\n",
    "for processed in processed_imagery:\n",
    "    df= pd.read_csv(processed)\n",
    "    con_ready_imagery.append(df)\n",
    "\n",
    "concatenated = pd.concat(con_ready_imagery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e02208-2077-4fef-a1e0-6bd15b6c1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated['geometry'] = concatenated['geometry'].apply(wkt.loads)\n",
    "gdf_processed = gpd.GeoDataFrame(concatenated, geometry = 'geometry', crs='EPSG:26912')\n",
    "gdf_processed['date'] = pd.to_datetime(gdf_processed['date'], format='%Y%m%d')\n",
    "gdf_processed['x'] = gdf_processed.geometry.x\n",
    "gdf_processed['y'] = gdf_processed.geometry.y\n",
    "gdf_processed = gdf_processed.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264da09-bd77-43ca-bb2d-745ea3af7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 6\n",
    "all_expanded['x'] = all_expanded['x'].round(precision)\n",
    "all_expanded['y'] = all_expanded['y'].round(precision)\n",
    "gdf_processed['x'] = gdf_processed['x'].round(precision)\n",
    "gdf_processed['y'] = gdf_processed['y'].round(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be3a98-d7b8-4d51-87b0-bc0de9e9dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = all_expanded.merge(gdf_processed, on=['date', 'x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482dd362-9c0c-4157-a19c-79cccbaee270",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.drop(columns = ['geometry_x', 'geometry_y', 'Imagery', 'date_first']) \n",
    "merged_sorted = merged.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e92102-0f4d-48a4-aee9-099e97f4410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sorted = merged_sorted.drop_duplicates()\n",
    "merged_sorted.dropna(inplace= True)\n",
    "merged_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6c9bd4-783b-41ba-b05c-42cf79881256",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "splitnum = 10\n",
    "for i in range(1,splitnum+1):\n",
    "    newstart = int(len(merged_sorted)/splitnum*i)\n",
    "    merged_sorted.iloc[start:newstart].to_csv('../data/Cienega/processed_assumptions/processed_with_dates_and_assumptions'+str(i)+'.csv',index=False,\n",
    "                      float_format='%.2f')\n",
    "    start = newstart\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d133df9-18c4-4e9c-981d-4964880e9bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b3a0b-8a5e-4568-895d-7862ed075ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f66fc-1c70-4c0a-ab30-a717d68f1fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e46e2e-5118-4db4-b2fd-0e844401787b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bcc12e-fac5-481b-ac05-0922f93cf7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701460e6-268d-4a31-b3f2-125b333b0787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
