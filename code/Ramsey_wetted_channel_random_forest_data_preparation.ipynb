{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHn8DGKUJ7Co"
   },
   "source": [
    "# Part 1: Initial data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpP5tUQeYMnY",
    "outputId": "cb24243d-5717-4356-8fff-be814387b99d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danalapides/opt/miniconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/danalapides/opt/miniconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# import required packages\n",
    "import pandas as pd\n",
    " #!pip install pandas fiona shapely pyproj rtree\n",
    "#!pip install pandas fiona shapely pyproj rtree\n",
    "#!pip install geopandas\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "#!pip install rasterio\n",
    "#import rasterio\n",
    "#from rasterio.plot import show\n",
    "import os\n",
    "import numpy as np\n",
    "from shapely.geometry import LineString\n",
    "from shapely.ops import unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YShWF2w-YYBs"
   },
   "outputs": [],
   "source": [
    "# these are survey data streamlines\n",
    "jsonfiles = os.listdir('../data/Ramsey/wetdry/survey_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFoq_aYWeT9Z",
    "outputId": "ec9775d7-f170-4e00-a477-cefaed856043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6-15-2015.geojson\n",
      "6-15-2023.geojson\n",
      "6-15-2022.geojson\n",
      "6-15-2014.geojson\n",
      "6-15-2020.geojson\n",
      "6-15-2016.geojson\n",
      "6-15-2021.geojson\n",
      "6-15-2012.geojson\n",
      "6-15-2013.geojson\n",
      "6-15-2018.geojson\n",
      "6-15-2009.geojson\n",
      "6-15-2019.geojson\n",
      "6-15-2010.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/3416420259.py:14: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  survey_boundary_geom = survey_boundary['geometry'].unary_union\n"
     ]
    }
   ],
   "source": [
    "# import data files\n",
    "geodata = {f:0 for f in jsonfiles}\n",
    "for f in jsonfiles:\n",
    "  print(f)\n",
    "  df = gpd.read_file('https://raw.githubusercontent.com/lapidesd/'+\n",
    "                     'SanPedro_wetdry_pilot/main/data/Ramsey/wetdry/survey_data/'+f).to_crs('EPSG:26912')\n",
    "  geodata[f] = df\n",
    "\n",
    "# wetted channel surveys\n",
    "surveylist = [geodata[key] for key in jsonfiles]\n",
    "\n",
    "# get geomorphic channel points for surveyed reach every 5 m\n",
    "survey_boundary = gpd.read_file('../data/Ramsey/ramsey_streamline.shp').to_crs('EPSG:26912')\n",
    "survey_boundary_geom = survey_boundary['geometry'].unary_union\n",
    "distance_delta = 5 # point every 5 m along line\n",
    "distances = np.arange(0,survey_boundary_geom.length, distance_delta)\n",
    "points = [survey_boundary_geom.interpolate(distance) for distance in distances]+[survey_boundary_geom.boundary.geoms[-1]]\n",
    "# multipoint = unary_union(points)\n",
    "geomorph = gpd.GeoDataFrame(pd.DataFrame.from_dict({'p':[0]*len(points)}),geometry=points).set_crs('EPSG:26912')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4gf0WHdHpkV",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Section 1: DO NOT RUN : Put together a dataset of nodes with PlanetScope data\n",
    "This cannot be run in Colab (would take days), and PlanetScope data is not available in the data supplement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LqEW_DvTH0w7"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../Ramsey/imagery/data_use/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# get list of imagery rasters available\u001b[39;00m\n\u001b[1;32m      2\u001b[0m imagery_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../Ramsey/imagery/data_use/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m rasters \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagery_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m rasters \u001b[38;5;241m=\u001b[39m [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rasters \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSR_clip.tif\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../Ramsey/imagery/data_use/'"
     ]
    }
   ],
   "source": [
    "# get list of imagery rasters available\n",
    "imagery_location = '../../Ramsey/imagery/data_use/'\n",
    "rasters = os.listdir(imagery_location)\n",
    "rasters = [r for r in rasters if r.endswith('SR_clip.tif')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMFOUvKWIVPh"
   },
   "outputs": [],
   "source": [
    "# function to extract PlanetScope zonal stats in buffer (buffer=True)\n",
    "# around geomorphic channel\n",
    "# or at geomorphic channel point (buffer=False)\n",
    "def query_raster(x,y, # GPS point\n",
    "                 point1, # GPS point (geometry type)\n",
    "                 raster, # satellite imagery\n",
    "                 buffer): # buffer area (# pixels) around channel point to grab data from\n",
    "    r = raster\n",
    "    band_data = {'blue':0,\n",
    "                   'geometry':0,\n",
    "                   'green':0,\n",
    "                   'red':0,\n",
    "                  #  'rededge':0,\n",
    "                   'NIR':0,\n",
    "                #  'Yellow':0,\n",
    "                #  'GreenI':0,\n",
    "                #  'CoastalBlue':0,\n",
    "                 'missing':0}\n",
    "    missing = 0\n",
    "    row, col = r.index(x,y) # find location of the gps point (x,y) in the raster image\n",
    "    if buffer:\n",
    "      rs = list(range(row-1,row+2))\n",
    "      cs = list(range(col-1,col+2))\n",
    "    else:\n",
    "      rs = [row]\n",
    "      cs = [col]\n",
    "    try:\n",
    "      blues = []\n",
    "      greens = []\n",
    "      reds = []\n",
    "      # rededges = []\n",
    "      nirs = []\n",
    "      for row in rs:\n",
    "        for col in cs:\n",
    "          blues.append(raster.read(1)[row,col])\n",
    "          greens.append(raster.read(2)[row,col])\n",
    "          reds.append(raster.read(3)[row,col])\n",
    "          # rededges.append(raster.read(4)[row,col])\n",
    "          nirs.append(raster.read(4)[row,col])\n",
    "\n",
    "      band_data['blue'] = np.nanmean(blues)\n",
    "      band_data['geometry'] = point1\n",
    "      band_data['green'] = np.nanmean(greens)\n",
    "      band_data['red'] = np.nanmean(reds)\n",
    "      # band_data['rededge'] = np.nanmean(rededges)\n",
    "      band_data['NIR'] = np.nanmean(nirs)\n",
    "    except:\n",
    "      missing = 1\n",
    "    band_data['missing'] = missing\n",
    "    return (band_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geomorph.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMiVSIgNH_zA"
   },
   "outputs": [],
   "source": [
    "# very slow --ran on local machine\n",
    "\n",
    "# gdfs = []\n",
    "!pip install multiprocess\n",
    "gdf = geomorph\n",
    "gdf['x'] = gdf.to_crs('EPSG:26912').geometry.x\n",
    "gdf['y'] = gdf.to_crs('EPSG:26912').geometry.y\n",
    "import rasterio\n",
    "def query_buffer(args):\n",
    "    cpu,cpus,rasters = args\n",
    "    for i in range(int(cpu/cpus*len(rasters)),int((cpu+1)/cpus*len(rasters))): # separate rasters onto separate cores\n",
    "        # print(i)\n",
    "        r1 = rasters[i]\n",
    "        #   print(i,'of',len(rasters))\n",
    "        date = r1.split('_')[0]\n",
    "        r = rasterio.open(imagery_location+r1)\n",
    "        out = gdf.apply(lambda row:query_raster(row.x,row.y,row.geometry,\n",
    "                                                                     r,buffer = True),axis=1)\n",
    "        keys = list(out.values[0].keys())\n",
    "        try:\n",
    "            band_data = pd.DataFrame.from_dict({keys[j]:[out.values[i][keys[j]] for i in range(len(out))]\n",
    "                                  for j in range(len(keys))})\n",
    "            band_data = band_data[band_data.missing==0]\n",
    "            band_data = gpd.GeoDataFrame(\n",
    "              band_data, geometry=band_data.geometry).set_crs('EPSG:26912')\n",
    "            band_data['NDWI'] = (band_data.green-band_data.NIR)/(band_data.green+band_data.NIR)\n",
    "            g = gpd.sjoin(band_data,gdf,how='left')\n",
    "            g = g.drop_duplicates().drop(columns='index_right')\n",
    "            g['date'] = date\n",
    "            g.to_file('../../Ramsey/imagery/buffer/'+r1[:-4]+'.tif')\n",
    "        except:\n",
    "            print('no geoms for',r1)\n",
    "    return\n",
    "\n",
    "import multiprocess as mp\n",
    "import sys\n",
    "\n",
    "\n",
    "cores = 8\n",
    "import time\n",
    "start_time = time.time()\n",
    "sys.stdout.write('\\r\\n')\n",
    "arguments = []\n",
    "for cpu in range(0,cores):\n",
    "    arguments.append((cpu,cores,rasters))\n",
    "pool = mp.Pool()\n",
    "results = pool.map(query_buffer, arguments)\n",
    "# r = query_buffer(arguments[0])\n",
    "extime = time.time()-start_time\n",
    "print(extime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzqGCJKQIC-K",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdfs = []\n",
    "for i in range(len(rasters)):\n",
    "    r = rasters[i]\n",
    "    print(i,' of',len(rasters))\n",
    "    try:\n",
    "        g = gpd.read_file('../../Ramsey/imagery/buffer/'+r[:-4]+'.tif/'+r[:-4]+'.shp')\n",
    "        gdfs.append(g)\n",
    "    except:\n",
    "        print('skipping '+r)\n",
    "gdf_predict = pd.concat(gdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gdf_predict['x'] = gdf_predict.to_crs('EPSG:4326').geometry.x*1000\n",
    "# gdf_predict['y'] = gdf_predict.to_crs('EPSG:4326').geometry.y*1000\n",
    "\n",
    "start = 0\n",
    "splitnum = 20\n",
    "for i in range(1,splitnum+1):\n",
    "    newstart = int(len(gdf_predict)/splitnum*i)\n",
    "    gdf_predict.iloc[start:newstart].drop(columns=['x','y']).to_csv('../data/Ramsey/processed_imagery/PSScope_data_buffer_'+str(i)+'.csv',index=False,\n",
    "                      float_format='%.2f')\n",
    "    start = newstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_predict = pd.concat(gdfs)\n",
    "# gdf_predict['date'] = pd.to_datetime([s[:4]+'-'+s[4:6]+'-'+s[6:] for s in gdf_predict['date']])\n",
    "# # gdf_predict.to_csv('../data/Ramsey/imagery/processed_imagery/PSScope_data_buffer.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../data/Ramsey/processed_imagery/PSScope_data_buffer_1.csv',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HthN1XonTJ4K"
   },
   "source": [
    "# Put together a dataset for training the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danalapides/opt/miniconda3/lib/python3.9/site-packages/pyogrio/raw.py:196: UserWarning: Measured (M) geometry types are not supported. Original type 'Measured LineString' is converted to 'LineString'\n",
      "  return ogr_read(\n",
      "/Users/danalapides/opt/miniconda3/lib/python3.9/site-packages/pyogrio/raw.py:196: UserWarning: Measured (M) geometry types are not supported. Original type 'Measured LineString' is converted to 'LineString'\n",
      "  return ogr_read(\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:9: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  wetyr = wet[wet.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:10: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  surveyyr = surveyed[surveyed.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:9: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  wetyr = wet[wet.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:10: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  surveyyr = surveyed[surveyed.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:9: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  wetyr = wet[wet.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:10: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  surveyyr = surveyed[surveyed.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:9: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  wetyr = wet[wet.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:10: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  surveyyr = surveyed[surveyed.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:9: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  wetyr = wet[wet.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:10: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  surveyyr = surveyed[surveyed.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:9: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  wetyr = wet[wet.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:10: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  surveyyr = surveyed[surveyed.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:9: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  wetyr = wet[wet.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:10: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  surveyyr = surveyed[surveyed.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:9: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  wetyr = wet[wet.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:10: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  surveyyr = surveyed[surveyed.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:9: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  wetyr = wet[wet.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:10: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  surveyyr = surveyed[surveyed.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:9: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  wetyr = wet[wet.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:10: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  surveyyr = surveyed[surveyed.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:9: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  wetyr = wet[wet.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:10: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  surveyyr = surveyed[surveyed.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:9: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  wetyr = wet[wet.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:10: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  surveyyr = surveyed[surveyed.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:9: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  wetyr = wet[wet.Year==y].geometry.unary_union\n",
      "/var/folders/9h/qhym8j_x3vlby3c3j9klp0vc0000gn/T/ipykernel_52042/2772127009.py:10: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  surveyyr = surveyed[surveyed.Year==y].geometry.unary_union\n",
      "/Users/danalapides/opt/miniconda3/lib/python3.9/site-packages/geopandas/array.py:1638: UserWarning: CRS not set for some of the concatenation inputs. Setting output's CRS as NAD83(HARN) / UTM zone 12N (the single non-null crs provided).\n",
      "  return GeometryArray(data, crs=_get_common_crs(to_concat))\n"
     ]
    }
   ],
   "source": [
    "import shapely\n",
    "surveyed = gpd.read_file('../data/Ramsey/wetdry/RamseyExport/Surveyed_Ramsey_1999_2023.shp')\n",
    "surveyed['Year'] = surveyed.Year.astype('int')\n",
    "wet = gpd.read_file('../data/Ramsey/wetdry/RamseyExport/Wet_Ramsey_1999_2023.shp')\n",
    "wet['Year'] = surveyed.Year.astype('int')\n",
    "wet['wetdry'] = 'wet'\n",
    "drysegments = []\n",
    "for y in surveyed.Year.unique():\n",
    "    wetyr = wet[wet.Year==y].geometry.unary_union\n",
    "    surveyyr = surveyed[surveyed.Year==y].geometry.unary_union\n",
    "    dryyr = surveyyr.difference(shapely.buffer(wetyr,.1))\n",
    "    drysegments.append(dryyr)\n",
    "dry = pd.DataFrame.from_dict({'Year':surveyed.Year.unique(),\n",
    "                              'geometry':drysegments})\n",
    "dry = gpd.GeoDataFrame(dry,geometry=dry.geometry)\n",
    "dry['wetdry'] = 'dry'\n",
    "wetdry = pd.concat([wet,dry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = 25 # m, max distance for error in merge-->this is too big\n",
    "surveyData = []\n",
    "\n",
    "for y in wetdry.Year.unique()[:]:\n",
    "    wsub = wetdry[(wetdry.Year==y) ].to_crs('EPSG:26912')\n",
    "    # dsub = wetdry[(wetdry.Year==y) & (wetdry.wetdry=='dry')].to_crs('EPSG:26912')\n",
    "    wetpts = gpd.sjoin_nearest(geomorph, wsub, max_distance=d,)\n",
    "    wetpts['Year'] = y\n",
    "    surveyData.append(wetpts)\n",
    "    drypts = wetpts[wetpts.wetdry=='dry']\n",
    "    wetpts = wetpts[wetpts.wetdry=='wet']\n",
    "    # drypts = gpd.sjoin_nearest(geomorph, dsub, max_distance = d)\n",
    "#     fig,ax = plt.subplots(1)\n",
    "#     geomorph.plot(ax=ax,markersize=1,label='geomorphic')\n",
    "#     wsub[wsub.wetdry=='wet'].plot(edgecolor = 'firebrick',ax=ax,label='wet line')\n",
    "#     wsub[wsub.wetdry=='dry'].plot(edgecolor = 'goldenrod',ax=ax,label='dry line')\n",
    "#     wetpts.plot(ax=ax,c='limegreen',markersize = 5,label='wet pts',alpha=.5)\n",
    "#     drypts.plot(ax=ax,c='k',markersize = 5, label='dry pts',alpha=.5)\n",
    "#     ax.legend()\n",
    "#     ax.set_title(y)\n",
    "#     plt.show()\n",
    "\n",
    "surveyData =pd.concat(surveyData)[['geometry','Year','wetdry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ignore this. my code is not tidy\n",
    "\n",
    "# numdone = len(os.listdir('../../Cienega/data/Imagery/buffer'))\n",
    "# numtodo = os.listdir('../../Cienega/data/Imagery/PSScene/')\n",
    "# numtodo = [p for p in numtodo if p.endswith('SR_clip.tif')]\n",
    "# numtodo = len(numtodo)\n",
    "# print(str(numdone)+' of '+str(numtodo)+': '+str(int(numdone/numtodo*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveyData.to_csv('../data/Ramsey/Ramsey_surveyData.csv', index = 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>Year</th>\n",
       "      <th>wetdry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>POINT (565860.782 3479494.933)</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>POINT (565857.412 3479491.24)</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>POINT (565854.042 3479487.546)</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>POINT (565850.672 3479483.853)</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>POINT (565847.302 3479480.159)</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>POINT (563919.024 3476832.283)</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>POINT (563918.293 3476837.229)</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>POINT (563917.563 3476842.175)</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>POINT (563916.832 3476847.122)</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>POINT (563916.101 3476852.068)</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>dry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13745 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            geometry    Year wetdry\n",
       "106   POINT (565860.782 3479494.933)  2020.0    dry\n",
       "107    POINT (565857.412 3479491.24)  2020.0    dry\n",
       "108   POINT (565854.042 3479487.546)  2020.0    dry\n",
       "109   POINT (565850.672 3479483.853)  2020.0    dry\n",
       "110   POINT (565847.302 3479480.159)  2020.0    dry\n",
       "...                              ...     ...    ...\n",
       "1440  POINT (563919.024 3476832.283)  2023.0    dry\n",
       "1441  POINT (563918.293 3476837.229)  2023.0    dry\n",
       "1442  POINT (563917.563 3476842.175)  2023.0    dry\n",
       "1443  POINT (563916.832 3476847.122)  2023.0    dry\n",
       "1444  POINT (563916.101 3476852.068)  2023.0    dry\n",
       "\n",
       "[13745 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surveyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = pd.read_csv('../data/Ramsey/processed_imagery/PSScope_data_buffer_1.csv')\n",
    "im['x'] = [float(im['geometry'].values[i].split()[1][1:]) for i in range(len(im))]\n",
    "im['y'] = [float(im['geometry'].values[i].split()[2][:-1]) for i in range(len(im))]\n",
    "im['date'] = pd.to_datetime(im.date,format='%Y%m%d')\n",
    "im = im[(im.blue>0) ]\n",
    "c = im.groupby(['geometry','date'])[['blue']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "      <th>NIR</th>\n",
       "      <th>missing</th>\n",
       "      <th>NDWI</th>\n",
       "      <th>p</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016-08-28</th>\n",
       "      <th>562487.769485</th>\n",
       "      <th>3.477327e+06</th>\n",
       "      <td>230.56</td>\n",
       "      <td>446.00</td>\n",
       "      <td>658.44</td>\n",
       "      <td>2554.89</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (562487.7694848299 3477326.738673826)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562492.716692</th>\n",
       "      <th>3.477327e+06</th>\n",
       "      <td>202.00</td>\n",
       "      <td>421.67</td>\n",
       "      <td>616.78</td>\n",
       "      <td>2445.56</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (562492.7166915945 3477327.463342874)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562497.663898</th>\n",
       "      <th>3.477328e+06</th>\n",
       "      <td>203.67</td>\n",
       "      <td>424.44</td>\n",
       "      <td>601.22</td>\n",
       "      <td>2502.67</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (562497.6638983592 3477328.188011921)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562502.611105</th>\n",
       "      <th>3.477329e+06</th>\n",
       "      <td>209.78</td>\n",
       "      <td>430.78</td>\n",
       "      <td>611.33</td>\n",
       "      <td>2512.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (562502.6111051238 3477328.912680968)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562507.558312</th>\n",
       "      <th>3.477330e+06</th>\n",
       "      <td>158.78</td>\n",
       "      <td>384.89</td>\n",
       "      <td>553.22</td>\n",
       "      <td>2366.44</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (562507.5583118884 3477329.6373500153)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2024-02-22</th>\n",
       "      <th>566229.271135</th>\n",
       "      <th>3.479841e+06</th>\n",
       "      <td>39.22</td>\n",
       "      <td>305.78</td>\n",
       "      <td>349.11</td>\n",
       "      <td>2185.78</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (566229.2711349044 3479841.1250762856)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566233.465618</th>\n",
       "      <th>3.479844e+06</th>\n",
       "      <td>43.11</td>\n",
       "      <td>331.22</td>\n",
       "      <td>365.67</td>\n",
       "      <td>2304.44</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (566233.4656179758 3479843.846530265)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566237.660101</th>\n",
       "      <th>3.479847e+06</th>\n",
       "      <td>63.56</td>\n",
       "      <td>390.56</td>\n",
       "      <td>441.33</td>\n",
       "      <td>2450.89</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (566237.6601010474 3479846.567984245)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566241.854584</th>\n",
       "      <th>3.479849e+06</th>\n",
       "      <td>92.44</td>\n",
       "      <td>373.44</td>\n",
       "      <td>493.89</td>\n",
       "      <td>2355.44</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (566241.8545841188 3479849.2894382244)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566246.049067</th>\n",
       "      <th>3.479852e+06</th>\n",
       "      <td>94.22</td>\n",
       "      <td>361.56</td>\n",
       "      <td>499.89</td>\n",
       "      <td>2248.78</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (566246.0490671904 3479852.010892204)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133228 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         blue   green     red      NIR  \\\n",
       "date       x             y                                               \n",
       "2016-08-28 562487.769485 3.477327e+06  230.56  446.00  658.44  2554.89   \n",
       "           562492.716692 3.477327e+06  202.00  421.67  616.78  2445.56   \n",
       "           562497.663898 3.477328e+06  203.67  424.44  601.22  2502.67   \n",
       "           562502.611105 3.477329e+06  209.78  430.78  611.33  2512.00   \n",
       "           562507.558312 3.477330e+06  158.78  384.89  553.22  2366.44   \n",
       "...                                       ...     ...     ...      ...   \n",
       "2024-02-22 566229.271135 3.479841e+06   39.22  305.78  349.11  2185.78   \n",
       "           566233.465618 3.479844e+06   43.11  331.22  365.67  2304.44   \n",
       "           566237.660101 3.479847e+06   63.56  390.56  441.33  2450.89   \n",
       "           566241.854584 3.479849e+06   92.44  373.44  493.89  2355.44   \n",
       "           566246.049067 3.479852e+06   94.22  361.56  499.89  2248.78   \n",
       "\n",
       "                                       missing  NDWI  p  \\\n",
       "date       x             y                                \n",
       "2016-08-28 562487.769485 3.477327e+06        0 -0.70  0   \n",
       "           562492.716692 3.477327e+06        0 -0.71  0   \n",
       "           562497.663898 3.477328e+06        0 -0.71  0   \n",
       "           562502.611105 3.477329e+06        0 -0.71  0   \n",
       "           562507.558312 3.477330e+06        0 -0.72  0   \n",
       "...                                        ...   ... ..   \n",
       "2024-02-22 566229.271135 3.479841e+06        0 -0.75  0   \n",
       "           566233.465618 3.479844e+06        0 -0.75  0   \n",
       "           566237.660101 3.479847e+06        0 -0.73  0   \n",
       "           566241.854584 3.479849e+06        0 -0.73  0   \n",
       "           566246.049067 3.479852e+06        0 -0.72  0   \n",
       "\n",
       "                                                                           geometry  \n",
       "date       x             y                                                           \n",
       "2016-08-28 562487.769485 3.477327e+06   POINT (562487.7694848299 3477326.738673826)  \n",
       "           562492.716692 3.477327e+06   POINT (562492.7166915945 3477327.463342874)  \n",
       "           562497.663898 3.477328e+06   POINT (562497.6638983592 3477328.188011921)  \n",
       "           562502.611105 3.477329e+06   POINT (562502.6111051238 3477328.912680968)  \n",
       "           562507.558312 3.477330e+06  POINT (562507.5583118884 3477329.6373500153)  \n",
       "...                                                                             ...  \n",
       "2024-02-22 566229.271135 3.479841e+06  POINT (566229.2711349044 3479841.1250762856)  \n",
       "           566233.465618 3.479844e+06   POINT (566233.4656179758 3479843.846530265)  \n",
       "           566237.660101 3.479847e+06   POINT (566237.6601010474 3479846.567984245)  \n",
       "           566241.854584 3.479849e+06  POINT (566241.8545841188 3479849.2894382244)  \n",
       "           566246.049067 3.479852e+06   POINT (566246.0490671904 3479852.010892204)  \n",
       "\n",
       "[133228 rows x 8 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = im.groupby(['date','x','y']).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next steps\n",
    "\n",
    "# goal: import satellite spectra information into the surveyData dataframe\n",
    "\n",
    "# add x, y columns to surveyData for merging\n",
    "\n",
    "# convert year to a survey date (6-15 on each year)\n",
    "\n",
    "# use Agnes's csv to find the imagery date to get data from for each row\n",
    "# merge into surveyData so we have an imagery date in each row--merge on survey date only (../data/Ramsey/processed_imagery)\n",
    "\n",
    "# before this block, read in all of the imagery data into one dataframe\n",
    "# (read in a loop, concatenate together)\n",
    "\n",
    "# merge imagery data into surveyData given imagery date--merge on geometry and imagery date\n",
    "\n",
    "# at the end of this block, you have training data for survey dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, expand the training data to other dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# everything below here is old code, don't worry about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XIM9qesGte30",
    "outputId": "b19b7cf3-d001-46f3-f4f1-ab2c1a2feefc"
   },
   "outputs": [],
   "source": [
    "wetsymbols1 = ['wet'] # list of symbols that mean wet\n",
    "\n",
    "# if point is assigned to wet and dry, assume wet\n",
    "\n",
    "# find points marked as wet during survey R1\n",
    "surveyR1 = pd.concat([geodata['Streamchannels_R1_2015_'+key] for key in\n",
    "                      ['Rock.geojson','Hank.geojson','Dry.geojson','Confluence.geojson']])\n",
    "# surveyR1wet = surveyR1[surveyR1.moisture.isin(wetsymbols1)]\n",
    "surveyR1['geometry'] = surveyR1.buffer(1.5)\n",
    "R1_wet = gpd.sjoin(gdf,surveyR1.to_crs('EPSG:4326')).drop(columns=['Length',])\n",
    "gdf1 = gpd.sjoin(R1_wet[['geometry','Moisture']],gdf,how='right').fillna(0)\n",
    "gdf1['wet'] = np.where(gdf1.Moisture.isin(wetsymbols1),1,0)\n",
    "gdf1 = gdf1.drop_duplicates()\n",
    "gdf1['wet'] = np.where(gdf1.drop(columns=['wet','Moisture']).duplicated(keep=False),1,gdf1.wet)\n",
    "gdf1 = gdf1[~(gdf1.drop(columns=['Moisture','wet']).duplicated(keep='first'))]\n",
    "gdf1.drop(columns=['index_left','Moisture'],inplace=True)\n",
    "# Date of nearest RapidEye image\n",
    "gdf1['date'] = pd.to_datetime('2015-06-04')\n",
    "\n",
    "\n",
    "# find points marked as wet during survey R2\n",
    "surveyR2 = pd.concat([geodata['Streamchannels_R2_2015_'+key] for key in\n",
    "                      ['Rock.geojson','Hank.geojson','Dry.geojson','Confluence.geojson']])\n",
    "# surveyR2wet = surveyR2[surveyR2.moisture.isin(wetsymbols2)]\n",
    "surveyR2['geometry'] = surveyR2.buffer(1.5)\n",
    "R2_wet = gpd.sjoin(gdf,surveyR2.to_crs('EPSG:4326')).drop(columns=['Length',])\n",
    "gdf2 = gpd.sjoin(R2_wet[['geometry','Moisture']],gdf1,how='right').fillna(0)\n",
    "gdf2['wet'] = np.where(gdf2.Moisture.isin(wetsymbols2),1,0)\n",
    "gdf2 = gdf2.drop_duplicates()\n",
    "gdf2['wet'] = np.where(gdf2.drop(columns=['wet','Moisture']).duplicated(keep=False),1,gdf2.wet)\n",
    "gdf2 = gdf2[~(gdf2.drop(columns=['Moisture','wet']).duplicated(keep='first'))]\n",
    "gdf2.drop(columns=['index_left','Moisture'],inplace=True)\n",
    "\n",
    "# Date of nearest RapidEye image\n",
    "gdf2['date'] = pd.to_datetime('2015-08-22')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyohn5ZwIspO"
   },
   "outputs": [],
   "source": [
    "testing = []\n",
    "for i in range(11):\n",
    "  testing.append(pd.read_csv('https://raw.githubusercontent.com/lapidesd/'+\n",
    "                                 'wetted_channels_from_space/main/Data/'+\n",
    "                                 'predict_data_'+str(i)+'.csv'))\n",
    "testing = pd.concat(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfk3qWdUAdBW"
   },
   "outputs": [],
   "source": [
    "gdf1 = gdf1.drop(columns=['date','geometry']).merge(testing[testing.date=='2015-06-04'],left_on=['x','y'],\n",
    "           right_on=['x','y']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "HsrWdJPvPcMj",
    "outputId": "7a44afad-0edc-49cb-a697-ab1da19307ad"
   },
   "outputs": [],
   "source": [
    "g1 = gdf1[(gdf1['wet']==1)&(gdf1.area_updated>100000)]\n",
    "g2 = gdf1[(gdf1['wet']==0)&(gdf1.area_updated>100000)]\n",
    "plt.scatter(g1.x,g1.y,s=1)\n",
    "plt.show()\n",
    "plt.scatter(g2.x,g2.y,s=1\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZOpRtMC7RJB"
   },
   "outputs": [],
   "source": [
    "gdf2 = gdf2.drop(columns=['date','geometry']).merge(testing[testing.date=='2015-08-22'],left_on=['x','y'],\n",
    "                  right_on=['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3c1jZDjY8o8H"
   },
   "outputs": [],
   "source": [
    "gdf3 = testing[testing.date=='2019-10-31']\n",
    "gdf['wet'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ALn4UDWU8zLR"
   },
   "outputs": [],
   "source": [
    "gdf4 = testing[testing.date=='2016-03-23']\n",
    "gdf['wet'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fvqOOBJ85Gb"
   },
   "outputs": [],
   "source": [
    "gdf5 = testing[testing.date=='2016-03-07']\n",
    "gdf['wet'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bc5YSq-E8-mO"
   },
   "outputs": [],
   "source": [
    "gdf6 = testing[testing.date=='2017-01-24']\n",
    "gdf['wet'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tkQUBMD2Ryp"
   },
   "outputs": [],
   "source": [
    "gdf_all = pd.concat([gdf1,gdf2,gdf3,gdf4,gdf5,gdf6]).drop(columns=['accum [m2]']).rename(\n",
    "                                                         columns={'datetime_x':'datetime',\n",
    "                                                                  'slope_percent_x':'slope_percent'}).fillna(0)\n",
    "gdf_all.to_csv('/content/drive/MyDrive/Sky_Data/combined_data_buffer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ly9U6YfnJ7Cz"
   },
   "source": [
    "# Part 2: processing initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLWCmjWcJl_U"
   },
   "outputs": [],
   "source": [
    "# # save original training data to github small size\n",
    "# # keep this block\n",
    "\n",
    "# training1 = training.drop(columns=['Unnamed: 0','Lithology_'])\n",
    "# len2 = int(len(training1)/2)+2\n",
    "# for i in range(2):\n",
    "#   training1.iloc[len2*i:len2*(i+1)+1].to_csv('temporary_training_'+str(i)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6sJZfiNI36A"
   },
   "outputs": [],
   "source": [
    "testing = []\n",
    "for i in range(11):\n",
    "  testing.append(pd.read_csv('https://raw.githubusercontent.com/lapidesd/'+\n",
    "                                 'wetted_channels_from_space/main/Data/'+\n",
    "                                 'predict_data_'+str(i)+'.csv'))\n",
    "testing = pd.concat(testing)\n",
    "testing = testing[~(testing.date.isin(testing))]\n",
    "\n",
    "training = []\n",
    "for i in range(2):\n",
    "  training.append(pd.read_csv('https://raw.githubusercontent.com/lapidesd/'+\n",
    "                              'wetted_channels_from_space/main/Data/'+\n",
    "                              'temporary_training_'+str(i)+'.csv'))\n",
    "training = pd.concat(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QiogfD59zhU_"
   },
   "outputs": [],
   "source": [
    "newarea = pd.read_csv('https://raw.githubusercontent.com/lapidesd/'+\n",
    "                      'wetted_channels_from_space/main/Data/'+\n",
    "                      'geomorphic_pts_newarea%202.csv')[['x','y','area_updated','slope_percent']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVfFA67SLJ9u"
   },
   "outputs": [],
   "source": [
    "# add an extra day to the training data (done date)\n",
    "# no longer relevant since using larger channels only\n",
    "\n",
    "new_data = testing[testing.date=='2018-02-12']\n",
    "new_data = new_data[new_data['area_updated']<20000]\n",
    "new_data['wet'] = 0\n",
    "new_training = pd.concat([training,new_data])\n",
    "\n",
    "new_training = new_training.drop_duplicates()\n",
    "\n",
    "# # save data\n",
    "# new_training.to_csv('/content/drive/MyDrive/Sky_Data/combined_data_buffer1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eMmAai5wFer"
   },
   "source": [
    "Add in more training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfhaTLc0ffui",
    "outputId": "203e6b28-f2bd-4b06-eae3-0549c72cad89"
   },
   "outputs": [],
   "source": [
    "!pip install hydrofunctions\n",
    "import hydrofunctions as hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6vH0yAiLguC",
    "outputId": "783b5c51-9d00-43c4-8ed6-8868f5e4a2d3"
   },
   "outputs": [],
   "source": [
    "elder = hf.NWIS('11475560',start_date='2015-06-01',end_date='2022-08-01',\n",
    "                parameterCd = '00060').df().rename(columns={'USGS:11475560:00060:00003':'flow_cfs'})\n",
    "survey_flow = elder.loc['2015-06-04'].flow_cfs\n",
    "dates_highflow = [str(t).split('T')[0] for t in elder[elder.flow_cfs>survey_flow*3].index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfMVmZmdJ7Cz"
   },
   "outputs": [],
   "source": [
    "df_test = testing.copy()\n",
    "df_train = new_training.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lKyTWB_EJ7Cz",
    "outputId": "3c343746-e23f-4f84-c73e-c134267094c8"
   },
   "outputs": [],
   "source": [
    "df_test['date'] = pd.to_datetime(df_test.date)\n",
    "zero_startyr = df_train[(df_train.date=='2015-06-04') &\n",
    "         (df_train.wet==0)]\n",
    "forward_test = df_test[(df_test.date>'2015-06-04') &\n",
    "        (df_test.date<'2015-08-22') &\n",
    "        (df_test.x.isin(zero_startyr.x.values)) &\n",
    "        (df_test.y.isin(zero_startyr.y.values))]\n",
    "forward_test['wet'] = 0\n",
    "one_endyr = df_train[(df_train.date=='2015-08-22') &\n",
    "         (df_train.wet==1)]\n",
    "back_test = df_test[(df_test.date>'2015-06-04') &\n",
    "        (df_test.date<'2015-08-22') &\n",
    "        (df_test.x.isin(one_endyr.x.values)) &\n",
    "        (df_test.y.isin(one_endyr.y.values))]\n",
    "back_test['wet'] = 1\n",
    "one_startyr = df_train[(df_train.date=='2015-06-04') &\n",
    "         (df_train.wet==1)]\n",
    "backearly_test = df_test[(df_test.date>'2015-03-15') &\n",
    "        (df_test.date<'2015-06-04') &\n",
    "        (df_test.x.isin(one_startyr.x.values)) &\n",
    "        (df_test.y.isin(one_startyr.y.values))]\n",
    "backearly_test['wet'] = 1\n",
    "forward_moresummer = df_test[(pd.to_datetime(df_test.date).dt.month.isin([7,8,9,10])) &\n",
    "                             (df_test.date.dt.year>2016) &\n",
    "        (df_test.x.isin(zero_startyr.x.values)) &\n",
    "        (df_test.y.isin(zero_startyr.y.values))]\n",
    "forward_moresummer['wet'] = 0\n",
    "\n",
    "# add more training data for wet times\n",
    "# (elder flow at least 3x elder flow at first survey)\n",
    "reallywet = df_test[(df_test.date.isin(dates_highflow)) &\n",
    "                    (df_test.x.isin(one_startyr.x.values)) &\n",
    "                    (df_test.y.isin(one_startyr.y.values))]\n",
    "reallywet['wet'] = 1\n",
    "\n",
    "\n",
    "\n",
    "# concatenate all of the new data\n",
    "added_data = pd.concat([df_train,back_test,forward_test,backearly_test,\n",
    "                        forward_moresummer,\n",
    "                        reallywet\n",
    "                        ])\n",
    "added_data = added_data.drop_duplicates()\n",
    "\n",
    "## fix 3-7-2016\n",
    "added_data = added_data[added_data.date!='2016-03-07']\n",
    "add_fixed_date = df_test[(df_test.date=='2016-03-07')]\n",
    "add_fixed_date['wet'] = 1\n",
    "added_data = pd.concat([added_data,add_fixed_date])\n",
    "\n",
    "# # save data\n",
    "# added_data.to_csv('/content/drive/MyDrive/Sky_Data/rapideye_train_data_buffer_moredata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iib1x27eMkwB"
   },
   "source": [
    "##ADD in a plot off all dates of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QSz-HpKyMm9b",
    "outputId": "8a49c76c-6eeb-4d83-a57e-96b45c07ade2"
   },
   "outputs": [],
   "source": [
    "added_data['date'] = pd.to_datetime(added_data.date)\n",
    "\n",
    "%matplotlib inline\n",
    "for date in added_data.date.sort_values().unique():\n",
    "  plotdata = added_data[(added_data.date==date) &\n",
    "                        (added_data.area_updated>100000)]\n",
    "  plt.figure()\n",
    "  plt.scatter(plotdata.x,plotdata.y,c=plotdata.wet,vmin=0,vmax=1,\n",
    "              s = 10)\n",
    "  plt.colorbar()\n",
    "  plt.title(date)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZbD_xBgdoP2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HthN1XonTJ4K"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
